import os
import json
import logging
import requests
import zipfile
import io
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from flask import Flask, request, jsonify
from flask_cors import CORS

# MCP Secrets í´ë˜ìŠ¤ ì‚¬ìš©
try:
    from app.core.secrets import Secrets
    _mcp_secrets = Secrets()
    
    # MCP Secretsì—ì„œ API í‚¤ ë¡œë“œ
    DART_API_KEY = _mcp_secrets.get_dart_key()
    PERPLEXITY_API_KEY = _mcp_secrets.get_perplexity_key()
    GPT_API_KEY = _mcp_secrets.get_gpt_key()
    
    print(f"âœ… MCP Secretsì—ì„œ API í‚¤ ë¡œë“œ ì„±ê³µ")
    
except Exception as e:
    print(f"âŒ MCP Secrets ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print("âŒ AWS Secrets Managerì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# API í‚¤ ë¡œë”© ê²°ê³¼ ë¡œê·¸
print(f"ğŸ” API í‚¤ ë¡œë”© ê²°ê³¼:")
print(f"   - DART_API_KEY: {'ì„¤ì •ë¨' if DART_API_KEY else 'None'} ({DART_API_KEY[:10] if DART_API_KEY else 'N/A'}...)")
print(f"   - PERPLEXITY_API_KEY: {'ì„¤ì •ë¨' if PERPLEXITY_API_KEY else 'None'} ({PERPLEXITY_API_KEY[:10] if PERPLEXITY_API_KEY else 'N/A'}...)")
print(f"   - GPT_API_KEY: {'ì„¤ì •ë¨' if GPT_API_KEY else 'None'} ({GPT_API_KEY[:10] if GPT_API_KEY else 'N/A'}...)")

# í•„ìˆ˜ í‚¤ ê²€ì¦ (ìµœì†Œ DART í‚¤) - ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ê²½ê³ ë§Œ í‘œì‹œ
if not DART_API_KEY:
    print("âš ï¸ DART_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    print("âš ï¸ ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤.")
    print("âš ï¸ ì‹¤ì œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” DART API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
else:
    print("âœ… DART_API_KEY ì„¤ì •ë¨")

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app, origins=["http://localhost:8080", "http://localhost:8081", "http://127.0.0.1:8080", "http://127.0.0.1:8081"])

# --- MCP ì½”ì–´ ì—°ë™ ì´ˆê¸°í™” ---
try:
    from app.core.dart_client import DartClient
    from app.core.services import FinancialService

    _DART_CLIENT = DartClient(DART_API_KEY)
    _MCP_SVC = FinancialService(_DART_CLIENT)
    
    # MCP ì´ˆê¸°í™” ìƒíƒœ ë¡œê·¸
    print(f"âœ… MCP ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
    print(f"   - DART API Key: {'ì„¤ì •ë¨' if DART_API_KEY else 'None'}")
    print(f"   - Perplexity API Key: {'ì„¤ì •ë¨' if PERPLEXITY_API_KEY else 'None'}")
    print(f"   - GPT API Key: {'ì„¤ì •ë¨' if GPT_API_KEY else 'None'}")
    
except Exception as _mcp_init_err:
    logger = logging.getLogger(__name__)
    logger.warning(f"MCP ì´ˆê¸°í™” ê²½ê³ : {getattr(_mcp_init_err, 'message', _mcp_init_err)}")
    print(f"âŒ MCP ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {_mcp_init_err}")
    _MCP_SVC = None

# DB API ì„œë²„ ì„¤ì • (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¹„í™œì„±í™”)
DB_API_BASE_URL = None  # ë¡œì»¬ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” DB ì €ì¥ ë¹„í™œì„±í™”
# DB_API_BASE_URL = "http://43.203.170.37:8080"  # ì‹¤ì œ ì„œë²„ ì£¼ì†Œ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ê¸€ë¡œë²Œ ìºì‹œ
CORP_CODE_CACHE = {}

def get_corp_code(corp_name: str) -> str:
    """ê¸°ì—… ê³ ìœ ë²ˆí˜¸ ì¡°íšŒ"""
    if corp_name in CORP_CODE_CACHE:
        return CORP_CODE_CACHE[corp_name]
    
    # DART API í‚¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê¸°ì—… ì½”ë“œ ë°˜í™˜
    if not DART_API_KEY:
        logger.warning(f"DART API í‚¤ê°€ ì—†ì–´ ê¸°ë³¸ ê¸°ì—… ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (corp_name: {corp_name})")
        # ì¼ë°˜ì ì¸ ê¸°ì—…ëª…ì— ëŒ€í•œ ê¸°ë³¸ ì½”ë“œ ë§¤í•‘
        default_codes = {
            'ì‚¼ì„±ì „ì': '00126380',
            'ì• í”Œ': '00126380',  # ì„ì‹œë¡œ ì‚¼ì„±ì „ì ì½”ë“œ ì‚¬ìš©
            'êµ¬ê¸€': '00126380',  # ì„ì‹œë¡œ ì‚¼ì„±ì „ì ì½”ë“œ ì‚¬ìš©
            'í…ŒìŠ¬ë¼': '00126380',  # ì„ì‹œë¡œ ì‚¼ì„±ì „ì ì½”ë“œ ì‚¬ìš©
        }
        return default_codes.get(corp_name, '00126380')  # ê¸°ë³¸ê°’: ì‚¼ì„±ì „ì
    
    try:
        zip_url = f'https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={DART_API_KEY}'
        response = requests.get(zip_url, timeout=30)
        
        with zipfile.ZipFile(io.BytesIO(response.content)) as zf:
            corp_bytes = zf.read('CORPCODE.xml')
            try:
                xml_str = corp_bytes.decode('euc-kr')
            except UnicodeDecodeError:
                xml_str = corp_bytes.decode('utf-8')
        
        root = ET.fromstring(xml_str)
        
        for item in root.findall('.//list'):
            name = item.find('corp_name').text
            code = item.find('corp_code').text
            
            if corp_name in name:
                CORP_CODE_CACHE[corp_name] = code
                return code
                
        raise ValueError(f"ê¸°ì—… '{corp_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        logger.error(f"ê¸°ì—… ì½”ë“œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise

def get_financial_data(corp_code: str, year: str = '2023') -> Dict:
    """ì¬ë¬´ì œí‘œ ë°ì´í„° ì¡°íšŒ - pandas ì—†ì´ ìˆœìˆ˜ Python ì‚¬ìš©"""
    # DART API í‚¤ê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
    if not DART_API_KEY:
        logger.warning(f"DART API í‚¤ê°€ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (corp_code: {corp_code}, year: {year})")
        return {
            'revenue': 1000000000000,  # 1ì¡°ì›
            'operating_profit': 100000000000,  # 1000ì–µì›
            'net_profit': 80000000000,  # 800ì–µì›
            'total_assets': 2000000000000,  # 2ì¡°ì›
            'total_debt': 800000000000,  # 8000ì–µì›
            'total_equity': 1200000000000  # 1.2ì¡°ì›
        }
    
    try:
        # ì˜¬ë°”ë¥¸ API ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
        url = 'https://opendart.fss.or.kr/api/fnlttSinglAcnt.json'
        params = {
            'crtfc_key': DART_API_KEY,
            'corp_code': corp_code,
            'bsns_year': year,
            'reprt_code': '11011'  # ì‚¬ì—…ë³´ê³ ì„œ (ì—°ê°„ ë°ì´í„°)
        }
        
        logger.info(f"DART API í˜¸ì¶œ: {url} with params: {params}")
        
        response = requests.get(url, params=params, timeout=30)
        
        logger.info(f"DART API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        
        if response.status_code != 200:
            raise ValueError(f"HTTP ì˜¤ë¥˜: {response.status_code}")
        
        data = response.json()
        logger.info(f"DART API ì‘ë‹µ ë°ì´í„°: status={data.get('status')}, message={data.get('message')}")
        
        if data['status'] != '000':
            raise ValueError(f"DART API ì˜¤ë¥˜: {data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        if 'list' not in data or not data['list']:
            raise ValueError(f"ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {year}ë…„ {corp_code}")
        
        # pandas ëŒ€ì‹  ìˆœìˆ˜ Python ì‚¬ìš©
        financial_list = data['list']
        financial_data = {}
        
        # CFS (ì—°ê²°ì¬ë¬´ì œí‘œ) ìš°ì„ , ì—†ìœ¼ë©´ OFS (ê°œë³„ì¬ë¬´ì œí‘œ) ì‚¬ìš©
        cfs_data = [item for item in financial_list if item.get('fs_div') == 'CFS']
        if not cfs_data:
            ofs_data = [item for item in financial_list if item.get('fs_div') == 'OFS']
            if ofs_data:
                filtered_data = ofs_data
                logger.info("CFS ì—†ìŒ, OFS ì‚¬ìš©")
            else:
                raise ValueError("ì—°ê²°ì¬ë¬´ì œí‘œ(CFS)ì™€ ê°œë³„ì¬ë¬´ì œí‘œ(OFS) ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤")
        else:
            filtered_data = cfs_data
            logger.info("CFS ì‚¬ìš©")
        
        # ì†ìµê³„ì‚°ì„œ(IS)ì—ì„œ ì£¼ìš” ì§€í‘œ ì¶”ì¶œ
        income_statement = [item for item in filtered_data if item.get('sj_div') == 'IS']
        if income_statement:
            # ë§¤ì¶œì•¡ ì°¾ê¸° (ë‹¤ì–‘í•œ ê³„ì •ëª… ê³ ë ¤)
            revenue_patterns = ['ë§¤ì¶œì•¡', 'ìˆ˜ìµ(ë§¤ì¶œì•¡)', 'ì˜ì—…ìˆ˜ìµ', 'ë§¤ì¶œ', 'ì´ë§¤ì¶œì•¡']
            for pattern in revenue_patterns:
                for item in income_statement:
                    account_nm = item.get('account_nm', '')
                    if pattern in account_nm:
                        amount = item.get('thstrm_amount', '')
                        if amount and amount != '-':
                            try:
                                financial_data['revenue'] = float(amount.replace(',', ''))
                                logger.info(f"ë§¤ì¶œì•¡ ë°œê²¬: {pattern} = {financial_data['revenue']}")
                                break
                            except ValueError:
                                continue
                if 'revenue' in financial_data:
                    break
            
            # ì˜ì—…ì´ìµ ì°¾ê¸°
            operating_patterns = ['ì˜ì—…ì´ìµ', 'ì˜ì—…ì†ìµ', 'ì˜ì—…ì´ìµ(ì†ì‹¤)']
            for pattern in operating_patterns:
                for item in income_statement:
                    account_nm = item.get('account_nm', '')
                    if pattern in account_nm:
                        amount = item.get('thstrm_amount', '')
                        if amount and amount != '-':
                            try:
                                financial_data['operating_profit'] = float(amount.replace(',', ''))
                                logger.info(f"ì˜ì—…ì´ìµ ë°œê²¬: {pattern} = {financial_data['operating_profit']}")
                                break
                            except ValueError:
                                continue
                if 'operating_profit' in financial_data:
                    break
            
            # ë‹¹ê¸°ìˆœì´ìµ ì°¾ê¸°
            net_patterns = ['ë‹¹ê¸°ìˆœì´ìµ', 'ìˆœì´ìµ', 'ë‹¹ê¸°ìˆœì†ìµ', 'ë‹¹ê¸°ìˆœì´ìµ(ì†ì‹¤)']
            for pattern in net_patterns:
                for item in income_statement:
                    account_nm = item.get('account_nm', '')
                    if pattern in account_nm:
                        amount = item.get('thstrm_amount', '')
                        if amount and amount != '-':
                            try:
                                financial_data['net_profit'] = float(amount.replace(',', ''))
                                logger.info(f"ë‹¹ê¸°ìˆœì´ìµ ë°œê²¬: {pattern} = {financial_data['net_profit']}")
                                break
                            except ValueError:
                                continue
                if 'net_profit' in financial_data:
                    break
        
        # ì¬ë¬´ìƒíƒœí‘œ(BS)ì—ì„œ ì£¼ìš” ì§€í‘œ ì¶”ì¶œ
        balance_sheet = [item for item in filtered_data if item.get('sj_div') == 'BS']
        if balance_sheet:
            # ìì‚°ì´ê³„ ì°¾ê¸°
            asset_patterns = ['ìì‚°ì´ê³„', 'ì´ìì‚°', 'ìì‚°í•©ê³„']
            for pattern in asset_patterns:
                for item in balance_sheet:
                    account_nm = item.get('account_nm', '')
                    if pattern in account_nm:
                        amount = item.get('thstrm_amount', '')
                        if amount and amount != '-':
                            try:
                                financial_data['total_assets'] = float(amount.replace(',', ''))
                                logger.info(f"ìì‚°ì´ê³„ ë°œê²¬: {pattern} = {financial_data['total_assets']}")
                                break
                            except ValueError:
                                continue
                if 'total_assets' in financial_data:
                    break
            
            # ë¶€ì±„ì´ê³„ ì°¾ê¸°
            debt_patterns = ['ë¶€ì±„ì´ê³„', 'ì´ë¶€ì±„', 'ë¶€ì±„í•©ê³„']
            for pattern in debt_patterns:
                for item in balance_sheet:
                    account_nm = item.get('account_nm', '')
                    if pattern in account_nm:
                        amount = item.get('thstrm_amount', '')
                        if amount and amount != '-':
                            try:
                                financial_data['total_debt'] = float(amount.replace(',', ''))
                                logger.info(f"ë¶€ì±„ì´ê³„ ë°œê²¬: {pattern} = {financial_data['total_debt']}")
                                break
                            except ValueError:
                                continue
                if 'total_debt' in financial_data:
                    break
            
            # ìë³¸ì´ê³„ ì°¾ê¸°
            equity_patterns = ['ìë³¸ì´ê³„', 'ì´ìë³¸', 'ìë³¸í•©ê³„', 'ìë³¸']
            for pattern in equity_patterns:
                for item in balance_sheet:
                    account_nm = item.get('account_nm', '')
                    if pattern in account_nm:
                        amount = item.get('thstrm_amount', '')
                        if amount and amount != '-':
                            try:
                                financial_data['total_equity'] = float(amount.replace(',', ''))
                                logger.info(f"ìë³¸ì´ê³„ ë°œê²¬: {pattern} = {financial_data['total_equity']}")
                                break
                            except ValueError:
                                continue
                if 'total_equity' in financial_data:
                    break
        
        logger.info(f"ì¶”ì¶œëœ ì¬ë¬´ ë°ì´í„°: {financial_data}")
        
        if not financial_data:
            raise ValueError("ìœ íš¨í•œ ì¬ë¬´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return financial_data
        
    except Exception as e:
        logger.error(f"ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise

def search_news_perplexity(company_name: str, period: str = '3days') -> List[Dict]:
    """Perplexity APIë¥¼ í†µí•´ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìš”ì•½ë§Œ ë°˜í™˜"""
    print(f"ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: {company_name} ({period})")
    print(f"   - PERPLEXITY_API_KEY: {'ì„¤ì •ë¨' if PERPLEXITY_API_KEY else 'None'} ({PERPLEXITY_API_KEY[:20] if PERPLEXITY_API_KEY else 'N/A'}...)")
    
    if not PERPLEXITY_API_KEY:
        print(f"âš ï¸ Perplexity API í‚¤ ì—†ìŒ - ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„° ë°˜í™˜")
        # ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„° ë°˜í™˜
        return [
            {
                'title': f'{company_name} 2024ë…„ 2ë¶„ê¸° ì‹¤ì  ë°œí‘œ',
                'content': f'{company_name}ì´ 2024ë…„ 2ë¶„ê¸° ì‹¤ì ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ë§¤ì¶œì€ ì „ë…„ ë™ê¸° ëŒ€ë¹„ 5% ì¦ê°€í–ˆìœ¼ë©°, ì˜ì—…ì´ìµì€ 10% ì„±ì¥ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.',
                'summary': f'{company_name} 2ë¶„ê¸° ì‹¤ì  í˜¸ì¡°, ë§¤ì¶œ 5% ì¦ê°€',
                'published_date': '2024-07-15',
                'source': 'ê²½ì œì¼ë³´',
                'url': 'https://example.com/news1'
            },
            {
                'title': f'{company_name} ì‹ ê·œ ì‚¬ì—… ì§„ì¶œ ì†Œì‹',
                'content': f'{company_name}ì´ ìƒˆë¡œìš´ ì‚¬ì—… ì˜ì—­ìœ¼ë¡œ ì§„ì¶œí•œë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤. íˆ¬ììë“¤ì€ ê¸ì •ì ì¸ ë°˜ì‘ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.',
                'summary': f'{company_name} ì‹ ê·œ ì‚¬ì—… ì§„ì¶œ, íˆ¬ìì ê¸ì •ì  ë°˜ì‘',
                'published_date': '2024-07-10',
                'source': 'ë¹„ì¦ˆë‹ˆìŠ¤ë‰´ìŠ¤',
                'url': 'https://example.com/news2'
            },
            {
                'title': f'{company_name} ì£¼ê°€ ìƒìŠ¹ì„¸',
                'content': f'{company_name} ì£¼ê°€ê°€ ìµœê·¼ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ì  ê°œì„ ê³¼ ì‹ ê·œ ì‚¬ì—… ì§„ì¶œ ì†Œì‹ì´ ê¸ì •ì ìœ¼ë¡œ ì‘ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
                'summary': f'{company_name} ì£¼ê°€ ìƒìŠ¹ì„¸, ì‹¤ì  ê°œì„  ê¸°ëŒ€ê°',
                'published_date': '2024-07-05',
                'source': 'ì¦ê¶Œì¼ë³´',
                'url': 'https://example.com/news3'
            }
        ]
    
    try:
        period_map = {'day': 'ì§€ë‚œ 24ì‹œê°„', '3days': 'ì§€ë‚œ 3ì¼', 'week': 'ì§€ë‚œ 7ì¼', 'month': 'ì§€ë‚œ 30ì¼'}
        period_text = period_map.get(period, 'ì§€ë‚œ 3ì¼')
        
        url = "https://api.perplexity.ai/chat/completions"
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # ëŒ€ì‹œë³´ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (contentì™€ summary ëª¨ë‘ í¬í•¨)
        prompt = f"""
{company_name}ì˜ {period_text} ì¬ë¬´, ì‹¤ì , íˆ¬ì ê´€ë ¨ ë‰´ìŠ¤ 5ê±´ì„ ë‹¤ìŒ JSON í˜•íƒœë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”:

{{
  "articles": [
    {{
      "title": "ê¸°ì‚¬ ì œëª©",
      "content": "ê¸°ì‚¬ ì „ì²´ ë‚´ìš© (ê°ì„±ë¶„ì„ìš©)",
      "summary": "í•µì‹¬ ë‚´ìš© 3ì¤„ ìš”ì•½",
      "published_date": "YYYY-MM-DD",
      "source": "ì–¸ë¡ ì‚¬ëª…",
      "url": "ê¸°ì‚¬ URL"
    }},
    {{
      "title": "ê¸°ì‚¬ ì œëª©",
      "content": "ê¸°ì‚¬ ì „ì²´ ë‚´ìš© (ê°ì„±ë¶„ì„ìš©)",
      "summary": "í•µì‹¬ ë‚´ìš© 3ì¤„ ìš”ì•½",
      "published_date": "YYYY-MM-DD",
      "source": "ì–¸ë¡ ì‚¬ëª…",
      "url": "ê¸°ì‚¬ URL"
    }},
    {{
      "title": "ê¸°ì‚¬ ì œëª©",
      "content": "ê¸°ì‚¬ ì „ì²´ ë‚´ìš© (ê°ì„±ë¶„ì„ìš©)",
      "summary": "í•µì‹¬ ë‚´ìš© 3ì¤„ ìš”ì•½",
      "published_date": "YYYY-MM-DD",
      "source": "ì–¸ë¡ ì‚¬ëª…",
      "url": "ê¸°ì‚¬ URL"
    }},
    {{
      "title": "ê¸°ì‚¬ ì œëª©",
      "content": "ê¸°ì‚¬ ì „ì²´ ë‚´ìš© (ê°ì„±ë¶„ì„ìš©)",
      "summary": "í•µì‹¬ ë‚´ìš© 3ì¤„ ìš”ì•½",
      "published_date": "YYYY-MM-DD",
      "source": "ì–¸ë¡ ì‚¬ëª…",
      "url": "ê¸°ì‚¬ URL"
    }},
    {{
      "title": "ê¸°ì‚¬ ì œëª©",
      "content": "ê¸°ì‚¬ ì „ì²´ ë‚´ìš© (ê°ì„±ë¶„ì„ìš©)",
      "summary": "í•µì‹¬ ë‚´ìš© 3ì¤„ ìš”ì•½",
      "published_date": "YYYY-MM-DD",
      "source": "ì–¸ë¡ ì‚¬ëª…",
      "url": "ê¸°ì‚¬ URL"
    }}
  ]
}}

ìš”êµ¬ì‚¬í•­:
1. ë°˜ë“œì‹œ ì¬ë¬´/ì‹¤ì /íˆ¬ì ê´€ë ¨ ë‰´ìŠ¤ë§Œ ì„ ë³„
2. content: ê¸°ì‚¬ ì „ì²´ ë‚´ìš© (ê°ì„±ë¶„ì„ìš©, 200-300ì)
3. summary: í•µì‹¬ ë‚´ìš© 3ì¤„ ìš”ì•½ (100ì ë‚´ì™¸)
4. ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” JSON ì´ìŠ¤ì¼€ì´í”„ ê·œì¹™ ì¤€ìˆ˜
"""
        
        data = {
            "model": "sonar-pro",
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¬ë¬´ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ê³ , summaryëŠ” ì •í™•íˆ 3ì¤„ë¡œ ì‘ì„±í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 2000,  # content í¬í•¨ìœ¼ë¡œ í† í° ìˆ˜ ì¦ê°€
            "temperature": 0.2
        }
        
        # API ìš”ì²­
        print(f"ğŸ“¡ Perplexity API ìš”ì²­ ì „ì†¡...")
        response = requests.post(url, headers=headers, json=data, timeout=30)
        print(f"ğŸ“¡ Perplexity API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        print(f"ğŸ“¡ Perplexity API ì‘ë‹µ ê¸¸ì´: {len(response.text)}")
        print(f"ğŸ“¡ Perplexity API ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {response.text[:500]}")
        print(f"ğŸ“¡ Perplexity API ì‘ë‹µ ë‚´ìš© (ë§ˆì§€ë§‰ 500ì): {response.text[-500:]}")
        
        if response.status_code == 200:
            result = response.json()
            
            # content ì¶”ì¶œ
            content = result['choices'][0].get('message', {}).get('content', '')
            
            # ë§Œì•½ contentê°€ ì—†ë‹¤ë©´ ì—ëŸ¬ ì²˜ë¦¬
            if not content:
                logger.error(f"Perplexity API ì‘ë‹µì— contentê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ë‹µ ë°ì´í„°: {json.dumps(result, ensure_ascii=False)}")
                return []
            
            try:
                # JSON íŒŒì‹±
                news_data = json.loads(content)
                articles = news_data.get('articles', [])
                
                if not articles:
                    logger.error(f"Perplexity APIì—ì„œ ë°˜í™˜ëœ articlesê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                    return []
                
                # ë°ì´í„° ì •ì œ (ëŒ€ì‹œë³´ë“œ í˜¸í™˜ì„± ìœ ì§€)
                processed_articles = []
                for article in articles[:5]:  # ìµœëŒ€ 5ê°œë§Œ
                    processed_article = {
                        'title': article.get('title', 'ì œëª© ì—†ìŒ')[:100],  # ì œëª© ê¸¸ì´ ì œí•œ
                        'summary': article.get('summary', 'ìš”ì•½ ì—†ìŒ')[:200],  # ìš”ì•½ ê¸¸ì´ ì œí•œ
                        'published_date': article.get('published_date', datetime.now().strftime('%Y-%m-%d')),
                        'source': article.get('source', 'ì¶œì²˜ ë¯¸ìƒ')[:50],
                        'url': article.get('url', '')[:200],
                        'content': article.get('content', article.get('summary', 'ë‚´ìš© ì—†ìŒ'))[:500]  # content ìš°ì„ , ì—†ìœ¼ë©´ summary ì‚¬ìš©
                    }
                    processed_articles.append(processed_article)
                
                print(f"âœ… ë‰´ìŠ¤ ê²€ìƒ‰ ì„±ê³µ: {len(processed_articles)}ê°œ ê¸°ì‚¬")
                return processed_articles
                
            except json.JSONDecodeError as e:
                print(f"âŒ Perplexity ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.error(f"Perplexity ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                
                # í´ë°±: MCP ë‰´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ì‹œë„
                try:
                    if _MCP_SVC is not None:
                        print(f"ğŸ”„ MCP ë‰´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ë¡œ í´ë°± ì‹œë„...")
                        import asyncio
                        mcp_result = asyncio.run(_MCP_SVC.get_company_news(
                            query=f"{company_name} ì¬ë¬´ ì‹¤ì  íˆ¬ì",
                            period=period
                        ))
                        
                        if mcp_result.get('ok'):
                            mcp_articles = mcp_result.get('data', {}).get('articles', [])
                            print(f"âœ… MCP ë‰´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì„±ê³µ: {len(mcp_articles)}ê°œ ê¸°ì‚¬")
                            
                            # MCP ê²°ê³¼ë¥¼ ë©”ì¸ ì„œë²„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            processed_articles = []
                            for i, article in enumerate(mcp_articles[:5]):
                                try:
                                    processed_article = {
                                        'title': str(article.get('title', 'ì œëª© ì—†ìŒ'))[:100],
                                        'content': str(article.get('content', 'ë‚´ìš© ì—†ìŒ'))[:500],
                                        'summary': str(article.get('summary', 'ìš”ì•½ ì—†ìŒ'))[:200],
                                        'published_date': str(article.get('published_date', datetime.now().strftime('%Y-%m-%d'))),
                                        'source': str(article.get('source', 'ì¶œì²˜ ë¯¸ìƒ'))[:50],
                                        'url': str(article.get('url', ''))[:200]
                                    }
                                    processed_articles.append(processed_article)
                                except Exception as e:
                                    print(f"âŒ MCP ê¸°ì‚¬ {i+1} ë³€í™˜ ì‹¤íŒ¨: {e}")
                                    continue
                            
                            return processed_articles
                        else:
                            print(f"âŒ MCP ë‰´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì‹¤íŒ¨: {mcp_result.get('error', 'Unknown error')}")
                except Exception as mcp_error:
                    print(f"âŒ MCP ë‰´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ í´ë°± ì‹¤íŒ¨: {mcp_error}")
                
                return []  # JSON íŒŒì‹± ï¿½ï¿½ï¿½íŒ¨ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
                
    except Exception as e:
        print(f"âŒ Perplexity API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        logger.error(f"Perplexity API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
 
    print(f"âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
    return []

def get_corp_name_from_dart(corp_code: str, year_range: str = None) -> str:
    """DART APIë¥¼ í†µí•´ corp_codeë¡œ corp_name ì¡°íšŒ - ì—°ë„ ê¸°ë°˜ ë™ì  ê²€ìƒ‰"""
    try:
        # ì—°ë„ ë²”ìœ„ì— ë”°ë¥¸ ê²€ìƒ‰ ê¸°ê°„ ì„¤ì •
        if year_range:
            try:
                start_year, end_year = year_range.split('-')
                bgn_de = f"{start_year}0101"
                end_de = f"{end_year}1231"
                print(f"ğŸ“… DART ê²€ìƒ‰ ê¸°ê°„ ì„¤ì •: {year_range}ë…„ ({bgn_de}~{end_de})")
            except Exception as e:
                print(f"âš ï¸ ì—°ë„ íŒŒì‹± ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
                bgn_de = '20240101'
                end_de = '20241231'
        else:
            bgn_de = '20240101'  # ê¸°ë³¸ê°’: ìµœê·¼ 1ë…„
            end_de = '20241231'
        
        url = 'https://opendart.fss.or.kr/api/list.json'
        params = {
            'crtfc_key': DART_API_KEY,
            'corp_code': corp_code,
            'bgn_de': bgn_de,
            'end_de': end_de,
            'pblntf_ty': 'A',  # ì •ê¸°ê³µì‹œ
            'page_no': 1,
            'page_count': 1  # 1ê±´ë§Œ ì¡°íšŒí•´ì„œ ê¸°ì—…ëª… í™•ì¸
        }
        
        response = requests.get(url, params=params, timeout=30)
        data = response.json()
        
        if data['status'] == '000' and data['list']:
            corp_name = data['list'][0]['corp_name']
            logger.info(f"DARTì—ì„œ ì¡°íšŒëœ ê¸°ì—…ëª…: {corp_name} (ì½”ë“œ: {corp_code})")
            return corp_name
        else:
            # ê³µì‹œê°€ ì—†ìœ¼ë©´ ê¸°ì—…ì½”ë“œ XMLì—ì„œ ì¡°íšŒ (ê¸°ì¡´ ë°©ì‹)
            logger.warning(f"DART ê³µì‹œ ëª©ë¡ì—ì„œ {corp_code} ê¸°ì—…ëª… ì¡°íšŒ ì‹¤íŒ¨, XML ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´")
            return get_corp_name_from_xml(corp_code)
            
    except Exception as e:
        logger.error(f"DART API ê¸°ì—…ëª… ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ XML ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´
        return get_corp_name_from_xml(corp_code)

def get_corp_name_from_xml(corp_code: str) -> str:
    """ê¸°ì¡´ XML ë°©ì‹ìœ¼ë¡œ ê¸°ì—…ëª… ì¡°íšŒ (ë°±ì—…ìš©)"""
    try:
        zip_url = f'https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={DART_API_KEY}'
        response = requests.get(zip_url, timeout=30)
        
        with zipfile.ZipFile(io.BytesIO(response.content)) as zf:
            corp_bytes = zf.read('CORPCODE.xml')
            try:
                xml_str = corp_bytes.decode('euc-kr')
            except UnicodeDecodeError:
                xml_str = corp_bytes.decode('utf-8')
        
        root = ET.fromstring(xml_str)
        
        for item in root.findall('.//list'):
            code = item.find('corp_code').text
            if code == corp_code:
                corp_name = item.find('corp_name').text
                return corp_name
                
        return f"ê¸°ì—…_{corp_code}"  # ìµœí›„ì˜ ëŒ€ì²´ê°’
        
    except Exception as e:
        logger.error(f"XMLì—ì„œ ê¸°ì—…ëª… ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return f"ê¸°ì—…_{corp_code}"

def _mcp_pick_value(rows: List[Dict], patterns: List[str]) -> float:
    for p in patterns:
        for r in rows:
            if p in r.get("ê³„ì •", ""):
                v = r.get("ë‹¹ê¸°")
                try:
                    return float(str(v).replace(",", "").replace("(", "-").replace(")", ""))
                except Exception:
                    pass
    return 0.0


def _mcp_extract_summary_from_statements(corp_code: str, year: str, year_range: str = None) -> Dict:
    if _MCP_SVC is None:
        # í´ë°±: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        print(f"âš ï¸ MCP ì„œë¹„ìŠ¤ ë¯¸ì‚¬ìš©, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ")
        return get_financial_data(corp_code, year)
    
    try:
        print(f"ğŸ” MCP ì¬ë¬´ì œí‘œ ì¡°íšŒ: {corp_code} ({year}ë…„, ë²”ìœ„: {year_range})")
        is_res = _MCP_SVC.get_financial_statements(
            corp_code=corp_code, bsns_year=year, reprt_code="11014", fs_div="CFS", statement_type="ì†ìµê³„ì‚°ì„œ"
        )
        bs_res = _MCP_SVC.get_financial_statements(
            corp_code=corp_code, bsns_year=year, reprt_code="11014", fs_div="CFS", statement_type="ì¬ë¬´ìƒíƒœí‘œ"
        )
        
        is_rows = is_res.get("data", []) if is_res.get("ok") else []
        bs_rows = bs_res.get("data", []) if bs_res.get("ok") else []
        
        if not is_rows and not bs_rows:
            print(f"âŒ MCP ì¬ë¬´ì œí‘œ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±")
            return get_financial_data(corp_code, year)
        
        result = {
            'revenue': _mcp_pick_value(is_rows, ['ë§¤ì¶œ','ë§¤ì¶œì•¡','ì˜ì—…ìˆ˜ìµ','ìˆ˜ìµ(ë§¤ì¶œì•¡)']),
            'operating_profit': _mcp_pick_value(is_rows, ['ì˜ì—…ì´ìµ','ì˜ì—…ì†ìµ','ì˜ì—…ì´ìµ(ì†ì‹¤)']),
            'net_profit': _mcp_pick_value(is_rows, ['ë‹¹ê¸°ìˆœì´ìµ','ë‹¹ê¸°ìˆœì´ìµ(ì†ì‹¤)','ìˆœì´ìµ']),
            'total_assets': _mcp_pick_value(bs_rows, ['ìì‚°ì´ê³„','ì´ìì‚°','ìì‚°í•©ê³„']),
            'total_debt': _mcp_pick_value(bs_rows, ['ë¶€ì±„ì´ê³„','ì´ë¶€ì±„','ë¶€ì±„í•©ê³„']),
            'total_equity': _mcp_pick_value(bs_rows, ['ìë³¸ì´ê³„','ì´ìë³¸','ìë³¸í•©ê³„','ìë³¸']),
        }
        
        print(f"âœ… MCP ì¬ë¬´ì œí‘œ ì¡°íšŒ ì„±ê³µ: ë§¤ì¶œ {result['revenue']:,.0f}ë°±ë§Œì›")
        return result
        
    except Exception as e:
        print(f"âŒ MCP ì¬ë¬´ì œí‘œ ì¡°íšŒ ì˜¤ë¥˜: {e}, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±")
        return get_financial_data(corp_code, year)


def generate_dashboard_data(corp_code: str, bgn_de: str, end_de: str, user_info: Dict) -> Dict:
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ë¡œì§ - MCP ì½”ì–´ ì‚¬ìš©(ê°€ëŠ¥ ì‹œ) + ê¸°ì¡´ ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ìœ ì§€"""
    # ì—°ë„ ë²”ìœ„ë¥¼ DART API ê²€ìƒ‰ì— ì „ë‹¬
    year_range = f"{bgn_de}-{end_de}"
    corp_name = get_corp_name_from_dart(corp_code, year_range)

    # í”„ë¡ íŠ¸ì—ì„œ ë°›ì€ ì—°ë„ ë²”ìœ„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    years = list(range(int(bgn_de), int(end_de) + 1))
    print(f"ğŸ“Š ìš”ì²­ëœ ì—°ë„ ë²”ìœ„: {bgn_de}-{end_de} ({len(years)}ë…„)")

    # MCPì˜ ì‹œê³„ì—´ ë¶„ì„ ì‚¬ìš© ì‹œë„
    years_sorted: List[str] = []
    revenue_trend: List[float] = []
    operating_profit_trend: List[float] = []
    net_profit_trend: List[float] = []

    if _MCP_SVC is not None:
        try:
            # MCP ì‹œê³„ì—´ ë¶„ì„ì€ ê³ ì •ëœ ë¡œì§ì´ë¯€ë¡œ, ìš”ì²­ëœ ì—°ë„ ë²”ìœ„ë¡œ ì§ì ‘ ë°ì´í„° ì¡°íšŒ
            print(f"ğŸ” ìš”ì²­ëœ ì—°ë„ ë²”ìœ„ë¡œ ì§ì ‘ ë°ì´í„° ì¡°íšŒ: {corp_code} ({year_range})")
            
            # ìš”ì²­ëœ ì—°ë„ ë²”ìœ„ë¡œ ì§ì ‘ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ
            years_sorted = []
            revenue_trend = []
            operating_profit_trend = []
            net_profit_trend = []
            
            for year in years:
                try:
                    print(f"  ğŸ“Š {year}ë…„ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì¤‘...")
                    financial_data = _mcp_extract_summary_from_statements(corp_code, str(year), year_range)
                    
                    years_sorted.append(str(year))
                    revenue_trend.append(financial_data.get('revenue', 0.0))
                    operating_profit_trend.append(financial_data.get('operating_profit', 0.0))
                    net_profit_trend.append(financial_data.get('net_profit', 0.0))
                    
                except Exception as e:
                    print(f"  âŒ {year}ë…„ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨í•œ ì—°ë„ëŠ” 0ìœ¼ë¡œ ì±„ì›€
                    years_sorted.append(str(year))
                    revenue_trend.append(0.0)
                    operating_profit_trend.append(0.0)
                    net_profit_trend.append(0.0)
            
            if years_sorted:
                print(f"âœ… ì—°ë„ë³„ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {len(years_sorted)}ë…„ ë°ì´í„°")
            else:
                print(f"âš ï¸ ì—°ë„ë³„ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ ì—°ë„ ì‚¬ìš©")
                years_sorted = [str(y) for y in sorted(years)]
                
        except Exception as e:
            print(f"âŒ ì—°ë„ë³„ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            years_sorted = [str(y) for y in sorted(years)]
    else:
        print(f"âš ï¸ MCP ì„œë¹„ìŠ¤ ë¯¸ì‚¬ìš©, ê¸°ë³¸ ì—°ë„ ì‚¬ìš©")
        years_sorted = [str(y) for y in sorted(years)]

    # ìµœì‹ ë…„ë„ ìš”ì•½
    latest_year = years_sorted[-1] if years_sorted else end_de
    latest_financial = _mcp_extract_summary_from_statements(corp_code, str(latest_year), year_range)



    # ë‰´ìŠ¤ ë°ì´í„° (ì‹¤ì‹œê°„ ìµœì‹  ë‰´ìŠ¤ ê³ ì •)
    news_articles = search_news_perplexity(corp_name, "3days")

    return {
        'company_info': {
            'corp_code': corp_code,
            'corp_name': corp_name,
            'analysis_period': f"{bgn_de}-{end_de}",
            'latest_year': latest_year
        },
        'financial_summary': {
            'revenue': latest_financial.get('revenue', 0),
            'operating_profit': latest_financial.get('operating_profit', 0),
            'net_profit': latest_financial.get('net_profit', 0),
            'total_assets': latest_financial.get('total_assets', 0),
            'total_debt': latest_financial.get('total_debt', 0),
            'total_equity': latest_financial.get('total_equity', 0)
        },

        'yearly_trends': {
            'years': years_sorted,
            'revenue': revenue_trend or [0.0]*len(years_sorted),
            'operating_profit': operating_profit_trend or [0.0]*len(years_sorted),
            'net_profit': net_profit_trend or [0.0]*len(years_sorted)
        },
        'news_data': {
            'total_articles': len(news_articles),
            'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M'),
            'has_news': len(news_articles) > 0,
            'status': 'success' if len(news_articles) > 0 else 'no_news_found',
            'articles': [
                {
                    'id': idx + 1,
                    'title': article['title'],
                    'summary': article['summary'],
                    'full_content': article['content'],
                    'published_date': article['published_date'],
                    'source': article['source'],
                    'url': article.get('url', ''),
                    'relevance': 'high'
                }
                for idx, article in enumerate(news_articles[:5])
            ] if len(news_articles) > 0 else [],
            'summary_stats': {
                'positive_news': len([a for a in news_articles if any(word in a.get('content', '').lower() for word in ['ì¦ê°€', 'ìƒìŠ¹', 'í˜¸ì¡°', 'ê°œì„ ', 'ì„±ì¥'])]) if news_articles else 0,
                'neutral_news': len([a for a in news_articles if not any(word in a.get('content', '').lower() for word in ['ì¦ê°€', 'ìƒìŠ¹', 'í˜¸ì¡°', 'ê°œì„ ', 'ì„±ì¥', 'ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”'])]) if news_articles else 0,
                'negative_news': len([a for a in news_articles if any(word in a.get('content', '').lower() for word in ['ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”'])]) if news_articles else 0
            } if len(news_articles) > 0 else {'positive_news': 0, 'neutral_news': 0, 'negative_news': 0},
            'message': 'ìµœì‹  ë‰´ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.' if len(news_articles) > 0 else (
                f'{corp_name}ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ' + 
                ('Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.' if not PERPLEXITY_API_KEY else 'Perplexity API ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.')
            )
        },
        'user_context': user_info,
        'generated_at': datetime.now().isoformat()
    }


@app.route('/api/news/<company_name>', methods=['GET'])
def get_company_news(company_name):
    """íŠ¹ì • ê¸°ì—…ì˜ ë‰´ìŠ¤ ì¡°íšŒ - ê°œì„ ëœ ë²„ì „"""
    try:
        period = request.args.get('period', '3days')
        limit = min(int(request.args.get('limit', 5)), 5)
        news_articles = search_news_perplexity(company_name, period)
        
        return jsonify({
            'status': 'success',
            'data': {
                'company_name': company_name,
                'period': period,
                'total_count': len(news_articles),
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M'),
                'articles': [
                    {
                        'id': idx + 1,
                        'title': article['title'],
                        'summary': article['summary'],
                        'full_content': article['content'],
                        'published_date': article['published_date'],
                        'source': article['source'],
                        'url': article.get('url', ''),
                        'word_count': len(article['content'].split())
                    }
                    for idx, article in enumerate(news_articles[:limit])
                ],
                'sentiment_analysis': {
                    'positive': len([a for a in news_articles if any(word in a.get('content', '').lower() for word in ['ì¦ê°€', 'ìƒìŠ¹', 'í˜¸ì¡°', 'ê°œì„ ', 'ì„±ì¥'])]),
                    'neutral': len([a for a in news_articles if not any(word in a.get('content', '').lower() for word in ['ì¦ê°€', 'ìƒìŠ¹', 'í˜¸ì¡°', 'ê°œì„ ', 'ì„±ì¥', 'ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”'])]),
                    'negative': len([a for a in news_articles if any(word in a.get('content', '').lower() for word in ['ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”'])])
                }
            }
        })
        
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

def save_chat_to_db(user_sno: str, message: str, response: str, chat_type: str = 'general') -> bool:
    """ì±„íŒ… ê¸°ë¡ì„ DB API ì„œë²„ì— ì €ì¥"""
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ DB ì €ì¥ ë¹„í™œì„±í™”
    if DB_API_BASE_URL is None:
        logger.info(f"ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: DB ì €ì¥ ê±´ë„ˆëœ€ (user_sno: {user_sno}, chat_type: {chat_type})")
        return True  # ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
    
    try:
        # user_snoê°€ ìˆ«ìì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜
        try:
            user_sno_int = int(user_sno)
        except ValueError:
            # ìˆ«ìê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            user_sno_int = 1
            logger.warning(f"user_sno '{user_sno}'ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ 1 ì‚¬ìš©")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        user_msg_response = requests.post(f'{DB_API_BASE_URL}/api/chat', 
            json={
                'user_sno': user_sno_int,
                'content': message,
                'role': 'user'
            },
            timeout=10
        )
        
        # AI ì‘ë‹µ ì €ì¥
        ai_msg_response = requests.post(f'{DB_API_BASE_URL}/api/chat',
            json={
                'user_sno': user_sno_int,
                'content': response,
                'role': 'assistant'
            },
            timeout=10
        )
        
        return user_msg_response.ok and ai_msg_response.ok
        
    except Exception as e:
        logger.error(f"DB ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def validate_user_exists(user_sno: str) -> bool:
    """ì‚¬ìš©ì ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¬ìš©ì ê²€ì¦ ë¹„í™œì„±í™”
    if DB_API_BASE_URL is None:
        logger.info(f"ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì‚¬ìš©ì ê²€ì¦ ê±´ë„ˆëœ€ (user_sno: {user_sno})")
        return True  # í•­ìƒ ì¡´ì¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬
    
    try:
        # user_snoê°€ ìˆ«ìì¸ì§€ í™•ì¸
        try:
            user_sno_int = int(user_sno)
        except ValueError:
            logger.warning(f"user_sno '{user_sno}'ê°€ ìˆ«ìê°€ ì•„ë‹˜, ì‚¬ìš©ì ê²€ì¦ ê±´ë„ˆëœ€")
            return True  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ True ë°˜í™˜
        
        response = requests.get(f'{DB_API_BASE_URL}/api/users/{user_sno_int}', timeout=10)
        return response.ok
    except Exception as e:
        logger.error(f"ì‚¬ìš©ì í™•ì¸ ì˜¤ë¥˜: {e}")
        return True  # ì˜¤ë¥˜ ì‹œì—ë„ ì§„í–‰í•˜ë„ë¡ True ë°˜í™˜

def call_llm_for_company_chat(message: str, user_info: Dict, company_data: Dict) -> str:
    """ê¸°ì—… ë¶„ì„ ì±„íŒ…ìš© LLM í˜¸ì¶œ - MCP ë™ì  ë°ì´í„° ì¡°íšŒ í¬í•¨"""
    if not GPT_API_KEY:
        return f"LLM API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. '{message}' ì§ˆë¬¸ì— ë‹µë³€í•˜ë ¤ë©´ GPT API ì—°ë™ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GPT_API_KEY}",
            "Content-Type": "application/json"
        }
        
        company_info = company_data.get('company_info', {})
        financial_summary = company_data.get('financial_summary', {})
        yearly_trends = company_data.get('yearly_trends', {})
        news_data = company_data.get('news_data', {})

        # MCP ì¬ë¬´ë¹„ìœ¨ í˜¸ì¶œ (ê°€ëŠ¥ ì‹œ)
        ratios = {}
        try:
            if _MCP_SVC is not None:
                print(f"ğŸ” MCP ì¬ë¬´ë¹„ìœ¨ ì¡°íšŒ: {company_info.get('corp_code', '')} ({company_info.get('latest_year', '')}ë…„)")
                ratios_res = _MCP_SVC.get_financial_ratios(
                    corp_code=company_info.get('corp_code', ''),
                    bsns_year=str(company_info.get('latest_year', '')) or str(datetime.now().year - 1)
                )
                if ratios_res.get('ok'):
                    ratios = ratios_res.get('data', {})
                    print(f"âœ… MCP ì¬ë¬´ë¹„ìœ¨ ì¡°íšŒ ì„±ê³µ: {ratios}")
                else:
                    print(f"âŒ MCP ì¬ë¬´ë¹„ìœ¨ ì¡°íšŒ ì‹¤íŒ¨: {ratios_res.get('error', 'Unknown error')}")
        except Exception as e:
            print(f"âŒ MCP ì¬ë¬´ë¹„ìœ¨ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            ratios = {}

        # ë™ì  MCP ë°ì´í„° ì¡°íšŒ - ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
        additional_data = {}
        mcp_queries = []
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì—°ë„ ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
        import re
        
        # ë‹¤ì–‘í•œ ì—°ë„ í‘œí˜„ íŒ¨í„´ ì§€ì›
        year_patterns = [
            r'(\d{4})ë…„',           # 2024ë…„
            r'(\d{4})ë…„ë„',         # 2024ë…„ë„
            r'(\d{4})',             # 2024
            r'(\d{4})ë…„\s*(\d{4})ë…„',  # 2022ë…„ 2024ë…„ (ë²”ìœ„)
        ]
        
        requested_year = str(company_info.get('latest_year', '') or datetime.now().year - 1)
        year_range = None
        
        for pattern in year_patterns:
            match = re.search(pattern, message)
            if match:
                if len(match.groups()) == 1:
                    requested_year = match.group(1)
                    print(f"ğŸ” ì‚¬ìš©ì ìš”ì²­ ì—°ë„ ì¶”ì¶œ: {requested_year}ë…„")
                    break
                elif len(match.groups()) == 2:
                    year_range = f"{match.group(1)}-{match.group(2)}"
                    requested_year = match.group(2)  # ìµœì‹  ì—°ë„ ì‚¬ìš©
                    print(f"ğŸ” ì‚¬ìš©ì ìš”ì²­ ì—°ë„ ë²”ìœ„ ì¶”ì¶œ: {year_range}ë…„")
                    break
        
        if not year_range:
            year_range = f"{requested_year}-{requested_year}"
        
        # 1. ì¬ë¬´ì œí‘œ ìš”ì²­ ê°ì§€ (í™•ì¥ëœ í‚¤ì›Œë“œ)
        statement_keywords = {
            'í˜„ê¸ˆíë¦„í‘œ': ['í˜„ê¸ˆíë¦„í‘œ', 'í˜„ê¸ˆíë¦„', 'cash flow', 'cf', 'í˜„ê¸ˆ'],
            'ì†ìµê³„ì‚°ì„œ': ['ì†ìµê³„ì‚°ì„œ', 'ì†ìµ', 'income statement', 'p&l', 'ì†ìµê³„ì‚°'],
            'ì¬ë¬´ìƒíƒœí‘œ': ['ì¬ë¬´ìƒíƒœí‘œ', 'ì¬ë¬´ìƒíƒœ', 'balance sheet', 'bs', 'ëŒ€ì°¨ëŒ€ì¡°í‘œ'],
            'ìë³¸ë³€ë™í‘œ': ['ìë³¸ë³€ë™í‘œ', 'ìë³¸ë³€ë™', 'ìë³¸ë³€í™”', 'equity', 'ìë³¸'],
        }
        
        for statement_type, keywords in statement_keywords.items():
            if any(keyword in message.lower() for keyword in keywords):
                mcp_queries.append((statement_type, 'get_financial_statements', {
                    'corp_code': company_info.get('corp_code', ''),
                    'bsns_year': requested_year,
                    'reprt_code': '11014',
                    'fs_div': 'CFS',
                    'statement_type': statement_type
                }))
                print(f"ğŸ” {statement_type} ìš”ì²­ ê°ì§€: {requested_year}ë…„")
        
        # 3. ê³µì‹œ ì •ë³´ ìš”ì²­ ê°ì§€ (í™•ì¥ëœ í‚¤ì›Œë“œ)
        if any(keyword in message.lower() for keyword in ['ê³µì‹œ', 'ê³µì‹œì •ë³´', 'ê³µì‹œë‚´ìš©', 'disclosure', 'ê³µì‹œëª©ë¡', 'ê³µì‹œìë£Œ', 'ê³µì‹œì„œë¥˜']):
            mcp_queries.append(('ê³µì‹œëª©ë¡', 'get_disclosure_list', {
                'corp_code': company_info.get('corp_code', ''),
                'bgn_de': f"{requested_year}0101",
                'end_de': f"{requested_year}1231",
                'page_count': 10
            }))
            print(f"ğŸ” ê³µì‹œì •ë³´ ìš”ì²­ ê°ì§€: {requested_year}ë…„")
        
        # 4. ì‹œê³„ì—´ ë¶„ì„ ìš”ì²­ ê°ì§€ (í™•ì¥ëœ í‚¤ì›Œë“œ)
        if any(keyword in message.lower() for keyword in ['íŠ¸ë Œë“œ', 'ì¶”ì´', 'ë³€í™”', 'ì„±ì¥', 'trend', 'ì¶”ì„¸', 'íë¦„', 'ì—°ë„ë³„', 'ê¸°ê°„ë³„', 'ì„±ì¥ë¥ ', 'ì¦ê°']):
            # ë¶„ì„ ê¸°ê°„ì„ ìš”ì²­ëœ ì—°ë„ ë²”ìœ„ë¡œ ì„¤ì •
            analysis_period = 2  # ê¸°ë³¸ê°’
            try:
                if year_range and '-' in year_range:
                    start_year, end_year = year_range.split('-')
                    analysis_period = int(end_year) - int(start_year) + 1
                else:
                    period_range = company_info.get('analysis_period', '')
                    if '-' in period_range:
                        start_year, end_year = period_range.split('-')
                        analysis_period = int(end_year) - int(start_year) + 1
            except:
                analysis_period = 2
            
            mcp_queries.append(('ì‹œê³„ì—´ë¶„ì„', 'analyze_time_series', {
                'corp_code': company_info.get('corp_code', ''),
                'analysis_period': analysis_period
            }))
            print(f"ğŸ” ì‹œê³„ì—´ë¶„ì„ ìš”ì²­ ê°ì§€: {analysis_period}ë…„")
        
        # 5. ê¸°ì—… ì •ë³´ ìš”ì²­ ê°ì§€ (í™•ì¥ëœ í‚¤ì›Œë“œ)
        if any(keyword in message.lower() for keyword in ['ê¸°ì—…ì •ë³´', 'íšŒì‚¬ì •ë³´', 'ê¸°ì—…ê°œìš”', 'company info', 'ê¸°ì—…ì†Œê°œ', 'íšŒì‚¬ì†Œê°œ', 'ê¸°ì—…í˜„í™©']):
            mcp_queries.append(('ê¸°ì—…ì •ë³´', 'get_company_info', {
                'corp_code': company_info.get('corp_code', '')
            }))
            print(f"ğŸ” ê¸°ì—…ì •ë³´ ìš”ì²­ ê°ì§€")
        
        # 6. ì¬ë¬´ë¹„ìœ¨ ìƒì„¸ ë¶„ì„ ìš”ì²­ ê°ì§€ (í™•ì¥ëœ í‚¤ì›Œë“œ)
        if any(keyword in message.lower() for keyword in ['ì¬ë¬´ë¹„ìœ¨', 'ë¹„ìœ¨ë¶„ì„', 'ROE', 'ROA', 'ë¶€ì±„ë¹„ìœ¨', 'financial ratio', 'ìˆ˜ìµì„±', 'ì•ˆì •ì„±', 'ì„±ì¥ì„±', 'ë¹„ìœ¨']):
            # ì¬ë¬´ë¹„ìœ¨ì€ ì´ë¯¸ ì¡°íšŒë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì¡°íšŒ ë¶ˆí•„ìš”
            print(f"ğŸ” ì¬ë¬´ë¹„ìœ¨ ë¶„ì„ ìš”ì²­ ê°ì§€ (ì´ë¯¸ ì¡°íšŒë¨)")
        
        # 7. ê²½ìŸì‚¬ ë¹„êµ ìš”ì²­ ê°ì§€ (í™•ì¥ëœ í‚¤ì›Œë“œ)
        if any(keyword in message.lower() for keyword in ['ê²½ìŸì‚¬', 'ë¹„êµ', 'peer', 'competitor', 'ë™ì¢…ì—…ê³„', 'ì—…ê³„ë¹„êµ', 'ê²½ìŸì—…ì²´']):
            # ê²½ìŸì‚¬ ë¹„êµëŠ” ë³„ë„ êµ¬í˜„ í•„ìš”
            print(f"ğŸ” ê²½ìŸì‚¬ ë¹„êµ ìš”ì²­ ê°ì§€ (ë¯¸êµ¬í˜„ ê¸°ëŠ¥)")
        
        # 8. ì¬ë¬´ì œí‘œ ì „ì²´ ìš”ì²­ ê°ì§€
        if any(keyword in message.lower() for keyword in ['ì¬ë¬´ì œí‘œ', 'ì¬ë¬´ì„œë¥˜', 'financial statements', 'ì¬ë¬´ë³´ê³ ì„œ']):
            # ëª¨ë“  ì¬ë¬´ì œí‘œ íƒ€ì… ì¡°íšŒ
            for statement_type in ['ì†ìµê³„ì‚°ì„œ', 'ì¬ë¬´ìƒíƒœí‘œ', 'í˜„ê¸ˆíë¦„í‘œ', 'ìë³¸ë³€ë™í‘œ']:
                mcp_queries.append((f"{statement_type}_ì „ì²´", 'get_financial_statements', {
                    'corp_code': company_info.get('corp_code', ''),
                    'bsns_year': requested_year,
                    'reprt_code': '11014',
                    'fs_div': 'CFS',
                    'statement_type': statement_type
                }))
            print(f"ğŸ” ì¬ë¬´ì œí‘œ ì „ì²´ ìš”ì²­ ê°ì§€: {requested_year}ë…„")
        
        # 9. ê¸°ì—… ë‰´ìŠ¤ ìš”ì²­ ê°ì§€
        if any(keyword in message.lower() for keyword in ['ë‰´ìŠ¤', 'ê¸°ì—…ë‰´ìŠ¤', 'ìµœì‹ ë‰´ìŠ¤', 'news', 'ê¸°ì‚¬', 'ì–¸ë¡ ë³´ë„']):
            mcp_queries.append(('ê¸°ì—…ë‰´ìŠ¤', 'get_company_news', {
                'query': f"{company_info.get('corp_name', '')} ì¬ë¬´ ì‹¤ì  íˆ¬ì",
                'period': 'week'
            }))
            print(f"ğŸ” ê¸°ì—…ë‰´ìŠ¤ ìš”ì²­ ê°ì§€")
        
        # 10. ë‰´ìŠ¤ ê°ì„±ë¶„ì„ ìš”ì²­ ê°ì§€
        if any(keyword in message.lower() for keyword in ['ê°ì„±ë¶„ì„', 'ë‰´ìŠ¤ë¶„ì„', 'ì—¬ë¡ ë¶„ì„', 'sentiment', 'ê¸ì •', 'ë¶€ì •']):
            mcp_queries.append(('ë‰´ìŠ¤ê°ì„±ë¶„ì„', 'analyze_news_sentiment', {
                'query': f"{company_info.get('corp_name', '')} ì¬ë¬´ ì‹¤ì  íˆ¬ì",
                'period': 'week'
            }))
            print(f"ğŸ” ë‰´ìŠ¤ê°ì„±ë¶„ì„ ìš”ì²­ ê°ì§€")
        
        # 11. ê²½ìŸì‚¬ ë¹„êµ ìš”ì²­ ê°ì§€ (êµ¬í˜„)
        if any(keyword in message.lower() for keyword in ['ê²½ìŸì‚¬', 'ë¹„êµ', 'peer', 'competitor', 'ë™ì¢…ì—…ê³„', 'ì—…ê³„ë¹„êµ', 'ê²½ìŸì—…ì²´']):
            # ê¸°ë³¸ ê²½ìŸì‚¬ ì½”ë“œ (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìê°€ ì§€ì •í•˜ê±°ë‚˜ ì—…ê³„ë³„ë¡œ ì„¤ì •)
            peer_codes = ['005930', '000660', '006400']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ì‚¼ì„±SDI
            mcp_queries.append(('ê²½ìŸì‚¬ë¹„êµ', 'analyze_competitive_position', {
                'corp_code': company_info.get('corp_code', ''),
                'peer_corp_codes': peer_codes
            }))
            print(f"ğŸ” ê²½ìŸì‚¬ë¹„êµ ìš”ì²­ ê°ì§€")
        
        # 12. ì—…ê³„ ë¦¬í¬íŠ¸ ìš”ì²­ ê°ì§€
        if any(keyword in message.lower() for keyword in ['ì—…ê³„', 'ì‚°ì—…', 'industry', 'ì„¹í„°', 'sector']):
            mcp_queries.append(('ì—…ê³„ë¦¬í¬íŠ¸', 'generate_industry_report', {
                'industry': 'ë°˜ë„ì²´'  # ê¸°ë³¸ê°’, ì‹¤ì œë¡œëŠ” ê¸°ì—… ì •ë³´ì—ì„œ ì¶”ì¶œ
            }))
            print(f"ğŸ” ì—…ê³„ë¦¬í¬íŠ¸ ìš”ì²­ ê°ì§€")
        
        # 13. í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ìš”ì²­ ê°ì§€
        if any(keyword in message.lower() for keyword in ['í¬íŠ¸í´ë¦¬ì˜¤', 'í¬íŠ¸í´ë¦¬ì˜¤', 'portfolio', 'ìì‚°ë°°ë¶„', 'íˆ¬ìë¹„ì¤‘']):
            # ê¸°ë³¸ í¬íŠ¸í´ë¦¬ì˜¤ (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìê°€ ì§€ì •)
            tickers = ['005930', '000660', '006400']  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ì‚¼ì„±SDI
            mcp_queries.append(('í¬íŠ¸í´ë¦¬ì˜¤ìµœì í™”', 'optimize_portfolio', {
                'tickers': tickers,
                'budget': 10000000,  # 1ì²œë§Œì›
                'risk': 'ë³´í†µ'
            }))
            print(f"ğŸ” í¬íŠ¸í´ë¦¬ì˜¤ìµœì í™” ìš”ì²­ ê°ì§€")
        
        # 14. ì¬ë¬´ë¹„ìœ¨ ìƒì„¸ ë¶„ì„ ìš”ì²­ ê°ì§€ (ì‹¤ì œ MCP í˜¸ì¶œ)
        if any(keyword in message.lower() for keyword in ['ì¬ë¬´ë¹„ìœ¨', 'ë¹„ìœ¨ë¶„ì„', 'ROE', 'ROA', 'ë¶€ì±„ë¹„ìœ¨', 'financial ratio', 'ìˆ˜ìµì„±', 'ì•ˆì •ì„±', 'ì„±ì¥ì„±', 'ë¹„ìœ¨']):
            mcp_queries.append(('ì¬ë¬´ë¹„ìœ¨ìƒì„¸', 'get_financial_ratios', {
                'corp_code': company_info.get('corp_code', ''),
                'bsns_year': requested_year,
                'reprt_code': '11014',
                'fs_div': 'CFS'
            }))
            print(f"ğŸ” ì¬ë¬´ë¹„ìœ¨ìƒì„¸ ë¶„ì„ ìš”ì²­ ê°ì§€: {requested_year}ë…„")
        
        # MCP ì¿¼ë¦¬ ì‹¤í–‰ (ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬)
        for query_name, query_type, params in mcp_queries:
            try:
                if _MCP_SVC is not None:
                    print(f"ğŸ” MCP {query_name} ì¡°íšŒ: {params}")
                    
                    if query_type == 'get_financial_statements':
                        result = _MCP_SVC.get_financial_statements(**params)
                    elif query_type == 'get_disclosure_list':
                        result = _MCP_SVC.get_disclosure_list(**params)
                    elif query_type == 'analyze_time_series':
                        result = _MCP_SVC.analyze_time_series(**params)
                    elif query_type == 'get_company_info':
                        result = _MCP_SVC.get_company_info(**params)
                    elif query_type == 'get_financial_ratios':
                        result = _MCP_SVC.get_financial_ratios(**params)
                    elif query_type == 'get_company_news':
                        # ë¹„ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                        import asyncio
                        try:
                            result = asyncio.run(_MCP_SVC.get_company_news(**params))
                        except Exception as e:
                            result = {"ok": False, "error": f"ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}
                    elif query_type == 'analyze_news_sentiment':
                        # ë¹„ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
                        import asyncio
                        try:
                            result = asyncio.run(_MCP_SVC.analyze_news_sentiment(**params))
                        except Exception as e:
                            result = {"ok": False, "error": f"ê°ì„±ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}
                    elif query_type == 'analyze_competitive_position':
                        result = _MCP_SVC.analyze_competitive_position(**params)
                    elif query_type == 'generate_industry_report':
                        result = _MCP_SVC.generate_industry_report(**params)
                    elif query_type == 'optimize_portfolio':
                        result = _MCP_SVC.optimize_portfolio(**params)
                    else:
                        print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” MCP ì¿¼ë¦¬ íƒ€ì…: {query_type}")
                        continue
                    
                    if result.get('ok'):
                        additional_data[query_name] = result.get('data', {})
                        print(f"âœ… MCP {query_name} ì¡°íšŒ ì„±ê³µ")
                    else:
                        error_msg = result.get('error', 'Unknown error')
                        additional_data[f"{query_name}_error"] = error_msg
                        print(f"âŒ MCP {query_name} ì¡°íšŒ ì‹¤íŒ¨: {error_msg}")
                        
                        # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì •ë³´ ì œê³µ
                        if 'no_data' in error_msg:
                            additional_data[f"{query_name}_note"] = f"{requested_year}ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                        elif 'section_missing' in error_msg:
                            additional_data[f"{query_name}_note"] = f"{params.get('statement_type', '')} ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤."
                        
            except Exception as e:
                error_msg = str(e)
                additional_data[f"{query_name}_error"] = error_msg
                print(f"âŒ MCP {query_name} ì¡°íšŒ ì˜¤ë¥˜: {error_msg}")
                
                # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“± êµ¬ì²´ì ì¸ ì•ˆë‚´
                if 'timeout' in error_msg.lower():
                    additional_data[f"{query_name}_note"] = "ë„¤íŠ¸ì›Œí¬ ì‹œê°„ ì´ˆê³¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                elif 'connection' in error_msg.lower():
                    additional_data[f"{query_name}_note"] = "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì¬ë¬´ì œí‘œ ë°ì´í„° ì²˜ë¦¬ (í™•ì¥ëœ ë¡œì§)
        financial_statements_data = {}
        
        # í˜„ê¸ˆíë¦„í‘œ ë°ì´í„° ì²˜ë¦¬
        if 'í˜„ê¸ˆíë¦„í‘œ' in additional_data:
            cf_rows = additional_data['í˜„ê¸ˆíë¦„í‘œ']
            cf_summary = {}
            for row in cf_rows:
                account = row.get('ê³„ì •', '')
                amount = row.get('ë‹¹ê¸°', 0)
                
                if 'ì˜ì—…í™œë™' in account and 'í˜„ê¸ˆíë¦„' in account:
                    cf_summary['ì˜ì—…í™œë™í˜„ê¸ˆíë¦„'] = amount
                elif 'íˆ¬ìí™œë™' in account and 'í˜„ê¸ˆíë¦„' in account:
                    cf_summary['íˆ¬ìí™œë™í˜„ê¸ˆíë¦„'] = amount
                elif 'ì¬ë¬´í™œë™' in account and 'í˜„ê¸ˆíë¦„' in account:
                    cf_summary['ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„'] = amount
                elif 'í˜„ê¸ˆ' in account and 'ì¦ê°' in account:
                    cf_summary['í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°ì¦ê°'] = amount
            
            financial_statements_data['í˜„ê¸ˆíë¦„í‘œ'] = cf_summary
        
        # ì†ìµê³„ì‚°ì„œ ë°ì´í„° ì²˜ë¦¬
        if 'ì†ìµê³„ì‚°ì„œ' in additional_data:
            is_rows = additional_data['ì†ìµê³„ì‚°ì„œ']
            is_summary = {}
            for row in is_rows:
                account = row.get('ê³„ì •', '')
                amount = row.get('ë‹¹ê¸°', 0)
                
                if 'ë§¤ì¶œ' in account:
                    is_summary['ë§¤ì¶œì•¡'] = amount
                elif 'ì˜ì—…ì´ìµ' in account:
                    is_summary['ì˜ì—…ì´ìµ'] = amount
                elif 'ë‹¹ê¸°ìˆœì´ìµ' in account:
                    is_summary['ë‹¹ê¸°ìˆœì´ìµ'] = amount
            
            financial_statements_data['ì†ìµê³„ì‚°ì„œ'] = is_summary
        
        # ì¬ë¬´ìƒíƒœí‘œ ë°ì´í„° ì²˜ë¦¬
        if 'ì¬ë¬´ìƒíƒœí‘œ' in additional_data:
            bs_rows = additional_data['ì¬ë¬´ìƒíƒœí‘œ']
            bs_summary = {}
            for row in bs_rows:
                account = row.get('ê³„ì •', '')
                amount = row.get('ë‹¹ê¸°', 0)
                
                if 'ìì‚°ì´ê³„' in account:
                    bs_summary['ì´ìì‚°'] = amount
                elif 'ë¶€ì±„ì´ê³„' in account:
                    bs_summary['ì´ë¶€ì±„'] = amount
                elif 'ìë³¸ì´ê³„' in account:
                    bs_summary['ì´ìë³¸'] = amount
            
            financial_statements_data['ì¬ë¬´ìƒíƒœí‘œ'] = bs_summary
        
        # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ cash_flow_data
        cash_flow_data = financial_statements_data.get('í˜„ê¸ˆíë¦„í‘œ', {})
        
        # ë™ì  ë°ì´í„° ì„¹ì…˜ ìƒì„± (í™•ì¥ëœ ë¡œì§)
        additional_sections = []
        
        # ì¬ë¬´ì œí‘œ ì„¹ì…˜ë“¤
        for statement_type, data in financial_statements_data.items():
            if statement_type == 'í˜„ê¸ˆíë¦„í‘œ' and data:
                # í˜„ê¸ˆíë¦„í‘œ ë°ì´í„° í¬ë§·íŒ…ì„ ë¯¸ë¦¬ ì²˜ë¦¬ (ì•ˆì „í•œ ë°©ì‹)
                try:
                    cf_operating = f"{float(data.get('ì˜ì—…í™œë™í˜„ê¸ˆíë¦„', 0)):,}"
                except (ValueError, TypeError):
                    cf_operating = "0"
                
                try:
                    cf_investing = f"{float(data.get('íˆ¬ìí™œë™í˜„ê¸ˆíë¦„', 0)):,}"
                except (ValueError, TypeError):
                    cf_investing = "0"
                
                try:
                    cf_financing = f"{float(data.get('ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„', 0)):,}"
                except (ValueError, TypeError):
                    cf_financing = "0"
                
                try:
                    cf_change = f"{float(data.get('í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°ì¦ê°', 0)):,}"
                except (ValueError, TypeError):
                    cf_change = "0"
                
                additional_sections.append(f"""
í˜„ê¸ˆíë¦„í‘œ ë°ì´í„° ({requested_year}ë…„):
- ì˜ì—…í™œë™í˜„ê¸ˆíë¦„: {cf_operating}ë°±ë§Œì›
- íˆ¬ìí™œë™í˜„ê¸ˆíë¦„: {cf_investing}ë°±ë§Œì›
- ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„: {cf_financing}ë°±ë§Œì›
- í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°ì¦ê°: {cf_change}ë°±ë§Œì›""")
            
            elif statement_type == 'ì†ìµê³„ì‚°ì„œ' and data:
                try:
                    revenue = f"{float(data.get('ë§¤ì¶œì•¡', 0)):,}"
                except (ValueError, TypeError):
                    revenue = "0"
                
                try:
                    operating_profit = f"{float(data.get('ì˜ì—…ì´ìµ', 0)):,}"
                except (ValueError, TypeError):
                    operating_profit = "0"
                
                try:
                    net_profit = f"{float(data.get('ë‹¹ê¸°ìˆœì´ìµ', 0)):,}"
                except (ValueError, TypeError):
                    net_profit = "0"
                
                additional_sections.append(f"""
ì†ìµê³„ì‚°ì„œ ë°ì´í„° ({requested_year}ë…„):
- ë§¤ì¶œì•¡: {revenue}ë°±ë§Œì›
- ì˜ì—…ì´ìµ: {operating_profit}ë°±ë§Œì›
- ë‹¹ê¸°ìˆœì´ìµ: {net_profit}ë°±ë§Œì›""")
            
            elif statement_type == 'ì¬ë¬´ìƒíƒœí‘œ' and data:
                try:
                    total_assets = f"{float(data.get('ì´ìì‚°', 0)):,}"
                except (ValueError, TypeError):
                    total_assets = "0"
                
                try:
                    total_debt = f"{float(data.get('ì´ë¶€ì±„', 0)):,}"
                except (ValueError, TypeError):
                    total_debt = "0"
                
                try:
                    total_equity = f"{float(data.get('ì´ìë³¸', 0)):,}"
                except (ValueError, TypeError):
                    total_equity = "0"
                
                additional_sections.append(f"""
ì¬ë¬´ìƒíƒœí‘œ ë°ì´í„° ({requested_year}ë…„):
- ì´ìì‚°: {total_assets}ë°±ë§Œì›
- ì´ë¶€ì±„: {total_debt}ë°±ë§Œì›
- ì´ìë³¸: {total_equity}ë°±ë§Œì›""")
        
        # ìë³¸ë³€ë™í‘œ ì„¹ì…˜
        if 'ìë³¸ë³€ë™í‘œ' in additional_data:
            equity_data = additional_data['ìë³¸ë³€ë™í‘œ']
            if equity_data:
                # ìë³¸ë³€ë™í‘œ ë°ì´í„° í¬ë§·íŒ…ì„ ë¯¸ë¦¬ ì²˜ë¦¬ (ì•ˆì „í•œ ë°©ì‹)
                equity_lines = []
                for row in equity_data[:5]:
                    account = row.get('ê³„ì •', '')
                    try:
                        amount = f"{float(row.get('ë‹¹ê¸°', 0)):,}"
                    except (ValueError, TypeError):
                        amount = "0"
                    equity_lines.append(f"- {account}: {amount}ë°±ë§Œì›")
                
                additional_sections.append(f"""
ìë³¸ë³€ë™í‘œ ë°ì´í„° ({requested_year}ë…„):
{chr(10).join(equity_lines)}""")
        
        # ê³µì‹œ ì •ë³´ ì„¹ì…˜
        if 'ê³µì‹œëª©ë¡' in additional_data:
            disclosure_data = additional_data['ê³µì‹œëª©ë¡']
            if disclosure_data:
                additional_sections.append(f"""
ìµœê·¼ ê³µì‹œ ì •ë³´ ({len(disclosure_data)}ê±´):
{chr(10).join([f"- {item.get('rcept_dt', '')}: {item.get('report_nm', '')}" for item in disclosure_data[:3]])}""")
        
        # ì‹œê³„ì—´ ë¶„ì„ ì„¹ì…˜
        if 'ì‹œê³„ì—´ë¶„ì„' in additional_data:
            ts_data = additional_data['ì‹œê³„ì—´ë¶„ì„']
            if ts_data:
                years = ts_data.get('years', [])
                series = ts_data.get('series', [])
                
                # ì‹œê³„ì—´ ë°ì´í„° í¬ë§·íŒ…ì„ ë¯¸ë¦¬ ì²˜ë¦¬ (ì•ˆì „í•œ ë°©ì‹)
                revenue_trend = []
                operating_profit_trend = []
                net_profit_trend = []
                
                for row in series:
                    try:
                        revenue_trend.append(f"{float(row.get('ë§¤ì¶œì•¡', 0)):,}")
                    except (ValueError, TypeError):
                        revenue_trend.append("0")
                    
                    try:
                        operating_profit_trend.append(f"{float(row.get('ì˜ì—…ì´ìµ', 0)):,}")
                    except (ValueError, TypeError):
                        operating_profit_trend.append("0")
                    
                    try:
                        net_profit_trend.append(f"{float(row.get('ìˆœì´ìµ', 0)):,}")
                    except (ValueError, TypeError):
                        net_profit_trend.append("0")
                
                additional_sections.append(f"""
ì‹œê³„ì—´ ë¶„ì„ ({len(years)}ë…„):
- ë¶„ì„ ì—°ë„: {years}
- ë§¤ì¶œì•¡ ì¶”ì´: {revenue_trend}
- ì˜ì—…ì´ìµ ì¶”ì´: {operating_profit_trend}
- ìˆœì´ìµ ì¶”ì´: {net_profit_trend}""")
        
        # ê¸°ì—… ì •ë³´ ì„¹ì…˜
        if 'ê¸°ì—…ì •ë³´' in additional_data:
            company_info_data = additional_data['ê¸°ì—…ì •ë³´']
            if company_info_data:
                additional_sections.append(f"""
ê¸°ì—… ê¸°ë³¸ ì •ë³´:
- ê¸°ì—…ëª…: {company_info_data.get('corp_name', '')}
- ì¢…ëª©ì½”ë“œ: {company_info_data.get('stock_code', '')}
- ì—…ì¢…: {company_info_data.get('sector', '')}
- ì„¤ë¦½ì¼: {company_info_data.get('establish_date', '')}""")
        
        # ê¸°ì—… ë‰´ìŠ¤ ì„¹ì…˜
        if 'ê¸°ì—…ë‰´ìŠ¤' in additional_data:
            news_data = additional_data['ê¸°ì—…ë‰´ìŠ¤']
            if news_data and news_data.get('articles'):
                articles = news_data.get('articles', [])
                news_lines = []
                for i, article in enumerate(articles[:3]):  # ìµœëŒ€ 3ê°œ
                    title = article.get('title', 'ì œëª© ì—†ìŒ')
                    summary = article.get('summary', 'ìš”ì•½ ì—†ìŒ')
                    news_lines.append(f"- {title}: {summary}")
                
                additional_sections.append(f"""
ìµœì‹  ê¸°ì—… ë‰´ìŠ¤ ({len(articles)}ê±´):
{chr(10).join(news_lines)}""")
        
        # ë‰´ìŠ¤ ê°ì„±ë¶„ì„ ì„¹ì…˜
        if 'ë‰´ìŠ¤ê°ì„±ë¶„ì„' in additional_data:
            sentiment_data = additional_data['ë‰´ìŠ¤ê°ì„±ë¶„ì„']
            if sentiment_data:
                total = sentiment_data.get('total', 0)
                positive = sentiment_data.get('positive', 0)
                negative = sentiment_data.get('negative', 0)
                sentiment = sentiment_data.get('sentiment', 'neutral')
                
                sentiment_kr = {'positive': 'ê¸ì •', 'negative': 'ë¶€ì •', 'neutral': 'ì¤‘ë¦½'}
                
                additional_sections.append(f"""
ë‰´ìŠ¤ ê°ì„±ë¶„ì„:
- ì´ ë‰´ìŠ¤: {total}ê±´
- ê¸ì •: {positive}ê±´
- ë¶€ì •: {negative}ê±´
- ì „ì²´ ê°ì„±: {sentiment_kr.get(sentiment, sentiment)}""")
        
        # ì¬ë¬´ë¹„ìœ¨ ìƒì„¸ ì„¹ì…˜
        if 'ì¬ë¬´ë¹„ìœ¨ìƒì„¸' in additional_data:
            ratios_data = additional_data['ì¬ë¬´ë¹„ìœ¨ìƒì„¸']
            if ratios_data:
                ratio_lines = []
                for ratio_name, ratio_value in ratios_data.items():
                    ratio_lines.append(f"- {ratio_name}: {ratio_value}%")
                
                additional_sections.append(f"""
ì¬ë¬´ë¹„ìœ¨ ìƒì„¸ ë¶„ì„ ({requested_year}ë…„):
{chr(10).join(ratio_lines)}""")
        
        # ê²½ìŸì‚¬ ë¹„êµ ì„¹ì…˜
        if 'ê²½ìŸì‚¬ë¹„êµ' in additional_data:
            competitive_data = additional_data['ê²½ìŸì‚¬ë¹„êµ']
            if competitive_data:
                corp_code = competitive_data.get('corp_code', '')
                peers = competitive_data.get('peers', [])
                summary = competitive_data.get('summary', 'ê¸°ë³¸ ë¹„êµ')
                
                additional_sections.append(f"""
ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„:
- ëŒ€ìƒ ê¸°ì—…: {corp_code}
- ë¹„êµ ëŒ€ìƒ: {len(peers)}ê°œ ê¸°ì—…
- ë¶„ì„ ìš”ì•½: {summary}""")
        
        # ì—…ê³„ ë¦¬í¬íŠ¸ ì„¹ì…˜
        if 'ì—…ê³„ë¦¬í¬íŠ¸' in additional_data:
            industry_data = additional_data['ì—…ê³„ë¦¬í¬íŠ¸']
            if industry_data:
                industry = industry_data.get('industry', '')
                highlights = industry_data.get('highlights', [])
                
                additional_sections.append(f"""
ì—…ê³„ ë¦¬í¬íŠ¸:
- ì—…ê³„: {industry}
- ì£¼ìš” íŠ¹ì§•: {', '.join(highlights)}""")
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì„¹ì…˜
        if 'í¬íŠ¸í´ë¦¬ì˜¤ìµœì í™”' in additional_data:
            portfolio_data = additional_data['í¬íŠ¸í´ë¦¬ì˜¤ìµœì í™”']
            if portfolio_data:
                weights = portfolio_data.get('weights', {})
                allocations = portfolio_data.get('allocations', {})
                risk = portfolio_data.get('risk', 'ë³´í†µ')
                
                weight_lines = []
                for ticker, weight in weights.items():
                    allocation = allocations.get(ticker, 0)
                    weight_lines.append(f"- {ticker}: {weight*100:.1f}% ({allocation:,}ì›)")
                
                additional_sections.append(f"""
í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”:
- ìœ„í—˜ë„: {risk}
- ìì‚° ë°°ë¶„:
{chr(10).join(weight_lines)}""")
        
        # MCP ì¡°íšŒ ì‹¤íŒ¨ ì •ë³´ (ê°œì„ ëœ ì²˜ë¦¬)
        mcp_errors = []
        mcp_notes = []
        
        for key, value in additional_data.items():
            if key.endswith('_error'):
                mcp_errors.append(f"- {key.replace('_error', '')}: {value}")
            elif key.endswith('_note'):
                mcp_notes.append(f"- {key.replace('_note', '')}: {value}")
        
        if mcp_errors:
            additional_sections.append(f"""
MCP ì¡°íšŒ ì‹¤íŒ¨ ì •ë³´:
{chr(10).join(mcp_errors)}""")
        
        if mcp_notes:
            additional_sections.append(f"""
MCP ì¡°íšŒ ì°¸ê³ ì‚¬í•­:
{chr(10).join(mcp_notes)}""")
        
        additional_data_section = chr(10).join(additional_sections)

        # ìˆ«ì í¬ë§·íŒ…ì„ ë¯¸ë¦¬ ì²˜ë¦¬í•˜ì—¬ ë¬¸ìì—´ í¬ë§·íŒ… ì¶©ëŒ ë°©ì§€ (ì•ˆì „í•œ ë°©ì‹)
        try:
            revenue_formatted = f"{float(financial_summary.get('revenue', 0)):,}"
        except (ValueError, TypeError):
            revenue_formatted = "0"
        
        try:
            operating_profit_formatted = f"{float(financial_summary.get('operating_profit', 0)):,}"
        except (ValueError, TypeError):
            operating_profit_formatted = "0"
        
        try:
            net_profit_formatted = f"{float(financial_summary.get('net_profit', 0)):,}"
        except (ValueError, TypeError):
            net_profit_formatted = "0"
        
        try:
            total_assets_formatted = f"{float(financial_summary.get('total_assets', 0)):,}"
        except (ValueError, TypeError):
            total_assets_formatted = "0"
        
        try:
            total_debt_formatted = f"{float(financial_summary.get('total_debt', 0)):,}"
        except (ValueError, TypeError):
            total_debt_formatted = "0"
        
        try:
            total_equity_formatted = f"{float(financial_summary.get('total_equity', 0)):,}"
        except (ValueError, TypeError):
            total_equity_formatted = "0"
        
        system_prompt = f"""ë‹¹ì‹ ì€ ì¬ë¬´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì¬ë¬´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.

ì‚¬ìš©ì: {user_info.get('nickname', 'ì‚¬ìš©ì')}
ë ˆë²¨: {user_info.get('difficulty', 'intermediate')}
ê´€ì‹¬ì‚¬: {user_info.get('interest', '')}
ëª©ì : {user_info.get('purpose', '')}

ë¶„ì„ ëŒ€ìƒ ê¸°ì—…: {company_info.get('corp_name', '')}
ë¶„ì„ ê¸°ê°„: {company_info.get('analysis_period', '')}ë…„

=== ê¸°ë³¸ ì¬ë¬´ ë°ì´í„° ===
ìµœì‹  ì¬ë¬´ ë°ì´í„° ({company_info.get('latest_year', '')}ë…„):
- ë§¤ì¶œì•¡: {revenue_formatted}ë°±ë§Œì›
- ì˜ì—…ì´ìµ: {operating_profit_formatted}ë°±ë§Œì›
- ìˆœì´ìµ: {net_profit_formatted}ë°±ë§Œì›
- ì´ìì‚°: {total_assets_formatted}ë°±ë§Œì›
- ì´ë¶€ì±„: {total_debt_formatted}ë°±ë§Œì›
- ì´ìë³¸: {total_equity_formatted}ë°±ë§Œì›

í•µì‹¬ ì¬ë¬´ë¹„ìœ¨: {ratios}

ì—°ë„ë³„ íŠ¸ë Œë“œ ({len(yearly_trends.get('years', []))}ë…„):
- ì—°ë„: {yearly_trends.get('years', [])}
- ë§¤ì¶œì•¡: {yearly_trends.get('revenue', [])}
- ì˜ì—…ì´ìµ: {yearly_trends.get('operating_profit', [])}
- ìˆœì´ìµ: {yearly_trends.get('net_profit', [])}

ë‰´ìŠ¤ ì •ë³´: {news_data.get('total_articles', 0)}ê±´ì˜ ìµœì‹  ê¸°ì‚¬ ë¶„ì„ë¨

=== ì¶”ê°€ ì¡°íšŒ ë°ì´í„° ===
{additional_data_section if additional_data_section else "ì¶”ê°€ ì¡°íšŒëœ ë°ì´í„° ì—†ìŒ"}

=== ë¶„ì„ ì§€ì¹¨ ===
1. ì œê³µëœ ëª¨ë“  ì¬ë¬´ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
2. ì¶”ê°€ ì¡°íšŒëœ ë°ì´í„°(í˜„ê¸ˆíë¦„í‘œ, ìë³¸ë³€ë™í‘œ, ê³µì‹œì •ë³´, ì‹œê³„ì—´ë¶„ì„ ë“±)ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë°ì´í„°ë¥¼ í¬í•¨í•œ ì¢…í•©ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
3. MCP ì¡°íšŒ ì‹¤íŒ¨ ì •ë³´ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë‚´ìš©ì„ ëª…ì‹œí•˜ê³ , ê°€ëŠ¥í•œ ë‹¤ë¥¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
4. ë°ì´í„°ê°€ 0ì´ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œí•˜ê³ , ê°€ëŠ¥í•œ ë‹¤ë¥¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
5. ì¬ë¬´ë¹„ìœ¨ì„ í™œìš©í•œ íˆ¬ì ê´€ì  ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”.
6. ì—°ë„ë³„ íŠ¸ë Œë“œê°€ ìˆìœ¼ë©´ ì„±ì¥/ê°ì†Œ ì¶”ì´ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
7. ë¶„ì„ ê¸°ê°„({company_info.get('analysis_period', '')}ë…„)ì„ ê³ ë ¤í•˜ì—¬ í•´ë‹¹ ê¸°ê°„ì˜ ì„±ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""

        data = {
            "model": "gpt-4o",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message}
            ],
            "max_tokens": 800,
            "temperature": 0.7
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            logger.error(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
    except Exception as e:
        logger.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def analyze_message_with_llm(message: str, user_info: Dict) -> Dict:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ì—ì„œ ê¸°ì—…ëª… ì–¸ê¸‰ ë° ì˜ë„ ë¶„ì„"""
    if not GPT_API_KEY:
        return {
            'has_company_mention': False,
            'mentioned_company': None,
            'intent': 'general',
            'confidence': 0.0
        }
    
    try:
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GPT_API_KEY}",
            "Content-Type": "application/json"
        }
        
        system_prompt = """ë‹¹ì‹ ì€ ë©”ì‹œì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”:

{
  "has_company_mention": boolean,  // ê¸°ì—…ëª…ì´ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€
  "mentioned_company": string or null,  // ì–¸ê¸‰ëœ ê¸°ì—…ëª… (ìˆëŠ” ê²½ìš°)
  "intent": string,  // "company_analysis", "general_finance", "other" ì¤‘ í•˜ë‚˜
  "confidence": float  // ë¶„ì„ ì‹ ë¢°ë„ (0.0 ~ 1.0)
}

ê¸°ì—…ëª… ì–¸ê¸‰ ê¸°ì¤€:
- êµ¬ì²´ì ì¸ íšŒì‚¬ëª… (ì‚¼ì„±ì „ì, ì• í”Œ, êµ¬ê¸€ ë“±)
- ê¸°ì—…/íšŒì‚¬/ì£¼ì‹íšŒì‚¬ ë“±ì˜ ì¼ë°˜ì  ì–¸ê¸‰
- íŠ¹ì • ì‚°ì—…ì˜ ê¸°ì—…ë“¤ì— ëŒ€í•œ ì§ˆë¬¸

ì˜ë„ ë¶„ë¥˜:
- company_analysis: íŠ¹ì • ê¸°ì—…ì˜ ì¬ë¬´/íˆ¬ì ë¶„ì„
- general_finance: ì¼ë°˜ì ì¸ ì¬ë¬´/íˆ¬ì ìƒë‹´
- other: ê¸°íƒ€"""

        data = {
            "model": "gpt-4o",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë¶„ì„í•  ë©”ì‹œì§€: '{message}'"}
            ],
            "max_tokens": 200,
            "temperature": 0.1
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            try:
                # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì´ ìˆì„ ìˆ˜ ìˆìŒ)
                if '```json' in content:
                    content = content.split('```json')[1].split('```')[0].strip()
                elif '```' in content:
                    content = content.split('```')[1].split('```')[0].strip()
                
                analysis_result = json.loads(content)
                return analysis_result
                
            except json.JSONDecodeError as e:
                logger.error(f"LLM ë¶„ì„ ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                
    except Exception as e:
        logger.error(f"LLM ë©”ì‹œì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    # ê¸°ë³¸ê°’ ë°˜í™˜
    return {
        'has_company_mention': False,
        'mentioned_company': None,
        'intent': 'general',
        'confidence': 0.0
    }

def call_llm_for_general_chat(message: str, user_info: Dict) -> str:
    """ì¼ë°˜ ì±„íŒ…ìš© LLM í˜¸ì¶œ"""
    if not GPT_API_KEY:
        return f"LLM API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. '{message}' ì§ˆë¬¸ì— ë‹µë³€í•˜ë ¤ë©´ GPT API ì—°ë™ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GPT_API_KEY}",
            "Content-Type": "application/json"
        }
        
        system_prompt = f"""ë‹¹ì‹ ì€ ì¬ë¬´ ë° íˆ¬ì ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì •ë³´:
- ë‹‰ë„¤ì„: {user_info.get('nickname', 'ì‚¬ìš©ì')}
- ë ˆë²¨: {user_info.get('difficulty', 'intermediate')}
- ê´€ì‹¬ì‚¬: {user_info.get('interest', '')}
- ëª©ì : {user_info.get('purpose', '')}

ì‚¬ìš©ìì˜ ë ˆë²¨ì— ë§ê²Œ ì¬ë¬´, íˆ¬ì, ê²½ì œì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ìœ ìš©í•œ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
êµ¬ì²´ì ì¸ ê¸°ì—… ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°, ê¸°ì—… ê²€ìƒ‰ì„ í†µí•´ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”."""

        data = {
            "model": "gpt-4o",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message}
            ],
            "max_tokens": 800,
            "temperature": 0.7
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            logger.error(f"GPT API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
    except Exception as e:
        logger.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ========== API ì—”ë“œí¬ì¸íŠ¸ë“¤ ==========

@app.route('/api/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0',
        'services': {
            'dart_api': bool(DART_API_KEY),
            'perplexity_api': bool(PERPLEXITY_API_KEY),
            'gpt_api': bool(GPT_API_KEY),
            'db_api': 'connected'  # DB API ì—°ê²° ìƒíƒœëŠ” ë³„ë„ ì²´í¬ ê°€ëŠ¥
        }
    })

@app.route('/api/dashboard', methods=['POST'])
def generate_dashboard():
    """ìˆœìˆ˜ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± (ë©”ì‹œì§€ ì—†ìŒ)"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'corp_code' not in data:
            return jsonify({'error': 'ê¸°ì—… ê³ ìœ ë²ˆí˜¸(corp_code)ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        corp_code = data['corp_code']
        bgn_de = data.get('bgn_de', '2019')
        end_de = data.get('end_de', '2023')
        
        # ì‚¬ìš©ì ì •ë³´ (ì„ íƒì )
        user_info = {
            'user_sno': data.get('user_sno', ''),
            'nickname': data.get('nickname', ''),
            'difficulty': data.get('difficulty', 'intermediate'),
            'interest': data.get('interest', ''),
            'purpose': data.get('purpose', '')
        }
        
        # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
        dashboard_data = generate_dashboard_data(corp_code, bgn_de, end_de, user_info)
        
        return jsonify(dashboard_data)
        
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat', methods=['POST'])
def chat_endpoint():
    """ì±„íŒ… API - chat_typeì— ë”°ë¼ ë¶„ê¸° ì²˜ë¦¬"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ['user_sno', 'nickname', 'difficulty', 'interest', 'purpose', 'chat_type', 'message']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'í•„ìˆ˜ ì •ë³´ ëˆ„ë½: {field}'}), 400
        
        # ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ
        user_info = {
            'user_sno': data['user_sno'],
            'nickname': data['nickname'],
            'difficulty': data['difficulty'],
            'interest': data['interest'],
            'purpose': data['purpose']
        }
        
        message = data['message']
        chat_type = data['chat_type']
        
        # ì‚¬ìš©ì ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì„ íƒì )
        if not validate_user_exists(user_info['user_sno']):
            logger.warning(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ìš©ì: {user_info['user_sno']}")
            # ê²½ê³ ë§Œ í•˜ê³  ê³„ì† ì§„í–‰ (DB ì„œë²„ ë‹¤ìš´ ì‹œì—ë„ ë™ì‘í•˜ë„ë¡)
        
        # chat_typeì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬
        if chat_type == 'company_analysis':
            # ê¸°ì—… ë¶„ì„ ì±„íŒ… - ëŒ€ì‹œë³´ë“œ ë°ì´í„° í•„ìš”
            if 'company_data' not in data:
                return jsonify({'error': 'ê¸°ì—… ë¶„ì„ì„ ìœ„í•´ company_dataê°€ í•„ìš”í•©ë‹ˆë‹¤. ë¨¼ì € /api/dashboardë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.'}), 400
            
            company_data = data['company_data']
            
            # LLMì„ í†µí•œ ê¸°ì—… ë¶„ì„ ë‹µë³€ ìƒì„±
            response_message = call_llm_for_company_chat(message, user_info, company_data)
            
            # ì±„íŒ… ê¸°ë¡ DBì— ì €ì¥
            save_success = save_chat_to_db(
                user_info['user_sno'], 
                message, 
                response_message, 
                'company_analysis'
            )
            
            return jsonify({
                'chat_type': 'company_analysis',
                'user_message': message,
                'response': response_message,
                'db_saved': save_success,
                'generated_at': datetime.now().isoformat()
            })
        
        elif chat_type == 'general_chat':
            # ì¼ë°˜ ì±„íŒ… - LLMì„ í†µí•œ ë©”ì‹œì§€ ë¶„ì„
            analysis_result = analyze_message_with_llm(message, user_info)
            
            if analysis_result['has_company_mention'] and analysis_result['intent'] == 'company_analysis':
                # ê¸°ì—… ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš° íŒì—… ìœ ë„
                response_message = "êµ¬ì²´ì ì¸ ê¸°ì—… ë¶„ì„ì„ ìœ„í•´ ì •í™•í•œ ê¸°ì—… ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ê¸°ì—…ì„ ê²€ìƒ‰í•˜ì—¬ ìƒì„¸í•œ ì¬ë¬´ ë¶„ì„ì„ ë°›ì•„ë³´ì„¸ìš”."
                
                # ì±„íŒ… ê¸°ë¡ ì €ì¥ (íŒì—… ìœ ë„ ë©”ì‹œì§€ë„ ì €ì¥)
                save_success = save_chat_to_db(user_info['user_sno'], message, response_message, 'general_popup')
                
                return jsonify({
                    'chat_type': 'general_chat',
                    'user_message': message,
                    'response': response_message,
                    'analysis': analysis_result,
                    'action_required': {
                        'type': 'open_company_search',
                        'popup_url': 'http://43.203.170.37:8080/compare/compSearchPopUp',
                        'suggested_company': analysis_result['mentioned_company']
                    },
                    'db_saved': save_success,
                    'generated_at': datetime.now().isoformat()
                })
            else:
                # ì¼ë°˜ì ì¸ ì¬ë¬´/íˆ¬ì ìƒë‹´
                response_message = call_llm_for_general_chat(message, user_info)
                
                # ì±„íŒ… ê¸°ë¡ ì €ì¥
                save_success = save_chat_to_db(
                    user_info['user_sno'], 
                    message, 
                    response_message, 
                    'general_chat'
                )
                
                return jsonify({
                    'chat_type': 'general_chat',
                    'user_message': message,
                    'response': response_message,
                    'analysis': analysis_result,
                    'db_saved': save_success,
                    'generated_at': datetime.now().isoformat()
                })
        
        else:
            # ì§€ì›í•˜ì§€ ì•ŠëŠ” chat_type
            return jsonify({'error': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” chat_type: {chat_type}'}), 400
    
    except Exception as e:
        logger.error(f"ì±„íŒ… API ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

# ========== ì¶”ê°€ ìœ í‹¸ë¦¬í‹° API ==========

@app.route('/api/company/search', methods=['GET'])
def search_company():
    """ê¸°ì—…ëª…ìœ¼ë¡œ ê¸°ì—… ì½”ë“œ ê²€ìƒ‰"""
    try:
        company_name = request.args.get('name')
        if not company_name:
            return jsonify({'error': 'ê¸°ì—…ëª…(name) íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        corp_code = get_corp_code(company_name)
        
        return jsonify({
            'status': 'success',
            'data': {
                'company_name': company_name,
                'corp_code': corp_code
            }
        })
        
    except Exception as e:
        logger.error(f"ê¸°ì—… ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 404

@app.route('/api/news/<company_name>', methods=['GET'])
def get_company_news_detailed(company_name):
    """íŠ¹ì • ê¸°ì—…ì˜ ë‰´ìŠ¤ ì¡°íšŒ - ê°œì„ ëœ ë²„ì „"""
    try:
        period = request.args.get('period', '3days')
        limit = min(int(request.args.get('limit', 5)), 5)  # ê¸°ë³¸ 5ê°œ, ìµœëŒ€ 5ê°œë¡œ ì œí•œ
        
        news_articles = search_news_perplexity(company_name, period)
        
        return jsonify({
            'status': 'success',
            'data': {
                'company_name': company_name,
                'period': period,
                'total_count': len(news_articles),
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M'),
                'articles': [
                    {
                        'id': idx + 1,
                        'title': article['title'],
                        'summary': article['summary'],
                        'full_content': article['content'],
                        'published_date': article['published_date'],
                        'source': article['source'],
                        'url': article.get('url', ''),
                        'word_count': len(article['content'].split())
                    }
                    for idx, article in enumerate(news_articles[:limit])
                ],
                'sentiment_analysis': {
                    'positive': len([a for a in news_articles if any(word in a.get('content', '').lower() for word in ['ì¦ê°€', 'ìƒìŠ¹', 'í˜¸ì¡°', 'ê°œì„ ', 'ì„±ì¥'])]),
                    'neutral': len([a for a in news_articles if not any(word in a.get('content', '').lower() for word in ['ì¦ê°€', 'ìƒìŠ¹', 'í˜¸ì¡°', 'ê°œì„ ', 'ì„±ì¥', 'ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”'])]),
                    'negative': len([a for a in news_articles if any(word in a.get('content', '').lower() for word in ['ê°ì†Œ', 'í•˜ë½', 'ë¶€ì§„', 'ì•…í™”'])])
                }
            }
        })
        
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/financial/<corp_code>/<year>', methods=['GET'])
def get_company_financial_data(corp_code, year):
    """íŠ¹ì • ê¸°ì—…ì˜ íŠ¹ì • ì—°ë„ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ"""
    try:
        financial_data = get_financial_data(corp_code, year)
        
        return jsonify({
            'status': 'success',
            'data': {
                'corp_code': corp_code,
                'year': year,
                'financial_data': financial_data
            }
        })
        
    except Exception as e:
        logger.error(f"ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

# ========== ì—ëŸ¬ í•¸ë“¤ëŸ¬ ==========

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'status': 'error',
        'message': 'API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        'available_endpoints': [
            'GET /api/health',
            'POST /api/dashboard',
            'POST /api/chat',
            'GET /api/company/search?name=ê¸°ì—…ëª…',
            'GET /api/news/<company_name>?period=month',
            'GET /api/financial/<corp_code>/<year>'
        ]
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'status': 'error',
        'message': 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
    }), 500

# ========== ê¸°ì—… ë¹„êµ ê¸°ëŠ¥ ì¶”ê°€ ==========

def get_company_financial_indicators(corp_code: str, year: str = '2023', quarter: str = '11011') -> Dict:
    """DART API - ë‹¤ì¤‘íšŒì‚¬ ì£¼ìš” ì¬ë¬´ì§€í‘œ ì¡°íšŒ"""
    try:
        # ì§€í‘œ ë¶„ë¥˜ ì½”ë“œ
        indicator_types = {
            'profitability': 'M210000',  # ìˆ˜ìµì„±ì§€í‘œ
            'stability': 'M220000',      # ì•ˆì •ì„±ì§€í‘œ  
            'growth': 'M230000',         # ì„±ì¥ì„±ì§€í‘œ
            'activity': 'M240000'        # í™œë™ì„±ì§€í‘œ
        }
        
        all_indicators = {}
        
        for category, idx_cl_code in indicator_types.items():
            url = 'https://opendart.fss.or.kr/api/fnlttCmpnyIndx.json'
            params = {
                'crtfc_key': DART_API_KEY,
                'corp_code': corp_code,
                'bsns_year': year,
                'reprt_code': quarter,
                'idx_cl_code': idx_cl_code
            }
            
            print(f"ì¬ë¬´ì§€í‘œ API í˜¸ì¶œ: {category} - {corp_code}")
            
            response = requests.get(url, params=params, timeout=30)
            data = response.json()
            
            if data['status'] == '000' and 'list' in data:
                category_indicators = {}
                for item in data['list']:
                    idx_nm = item.get('idx_nm', '')
                    idx_val = item.get('idx_val', '')
                    
                    # ìˆ«ì ê°’ìœ¼ë¡œ ë³€í™˜ ì‹œë„
                    try:
                        if idx_val and idx_val != '-':
                            category_indicators[idx_nm] = float(idx_val)
                        else:
                            category_indicators[idx_nm] = None
                    except (ValueError, TypeError):
                        category_indicators[idx_nm] = idx_val
                
                all_indicators[category] = category_indicators
            else:
                print(f"{category} ì§€í‘œ ì¡°íšŒ ì‹¤íŒ¨: {data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                all_indicators[category] = {}
        
        return all_indicators
        
    except Exception as e:
        print(f"ì¬ë¬´ì§€í‘œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {
            'profitability': {},
            'stability': {},
            'growth': {},
            'activity': {}
        }

def get_company_major_accounts(corp_code: str, year: str = '2023', quarter: str = '11011') -> Dict:
    """DART API - ë‹¤ì¤‘íšŒì‚¬ ì£¼ìš”ê³„ì • ì¡°íšŒ"""
    try:
        url = 'https://opendart.fss.or.kr/api/fnlttMultiAcnt.json'
        params = {
            'crtfc_key': DART_API_KEY,
            'corp_code': corp_code,
            'bsns_year': year,
            'reprt_code': quarter
        }
        
        print(f"ì£¼ìš”ê³„ì • API í˜¸ì¶œ: {corp_code}")
        
        response = requests.get(url, params=params, timeout=30)
        data = response.json()
        
        if data['status'] != '000':
            raise ValueError(f"ì£¼ìš”ê³„ì • API ì˜¤ë¥˜: {data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        if 'list' not in data or not data['list']:
            raise ValueError(f"ì£¼ìš”ê³„ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {year}ë…„ {corp_code}")
        
        accounts_data = data['list']
        
        # CFS (ì—°ê²°ì¬ë¬´ì œí‘œ) ìš°ì„ , ì—†ìœ¼ë©´ OFS (ê°œë³„ì¬ë¬´ì œí‘œ) ì‚¬ìš©
        cfs_data = [item for item in accounts_data if item.get('fs_div') == 'CFS']
        if not cfs_data:
            ofs_data = [item for item in accounts_data if item.get('fs_div') == 'OFS']
            if ofs_data:
                filtered_data = ofs_data
            else:
                raise ValueError("ì—°ê²°ì¬ë¬´ì œí‘œ(CFS)ì™€ ê°œë³„ì¬ë¬´ì œí‘œ(OFS) ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤")
        else:
            filtered_data = cfs_data
        
        # ì£¼ìš” ê³„ì • ì¶”ì¶œ
        major_accounts = {
            'balance_sheet': {},  # ì¬ë¬´ìƒíƒœí‘œ
            'income_statement': {}  # ì†ìµê³„ì‚°ì„œ
        }
        
        # ì¬ë¬´ìƒíƒœí‘œ ê³„ì •ë“¤
        bs_accounts = [item for item in filtered_data if item.get('sj_div') == 'BS']
        for item in bs_accounts:
            account_nm = item.get('account_nm', '')
            amount = item.get('thstrm_amount', '')
            
            try:
                if amount and amount != '-':
                    major_accounts['balance_sheet'][account_nm] = float(amount.replace(',', ''))
                else:
                    major_accounts['balance_sheet'][account_nm] = 0
            except (ValueError, AttributeError):
                major_accounts['balance_sheet'][account_nm] = 0
        
        # ì†ìµê³„ì‚°ì„œ ê³„ì •ë“¤  
        is_accounts = [item for item in filtered_data if item.get('sj_div') == 'IS']
        for item in is_accounts:
            account_nm = item.get('account_nm', '')
            amount = item.get('thstrm_amount', '')
            
            try:
                if amount and amount != '-':
                    major_accounts['income_statement'][account_nm] = float(amount.replace(',', ''))
                else:
                    major_accounts['income_statement'][account_nm] = 0
            except (ValueError, AttributeError):
                major_accounts['income_statement'][account_nm] = 0
        
        return major_accounts
        
    except Exception as e:
        print(f"ì£¼ìš”ê³„ì • ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {
            'balance_sheet': {},
            'income_statement': {}
        }

def generate_comparison_dashboard(corp_code1: str, corp_code2: str, year: str = '2023', quarter: str = '11011') -> Dict:
    """ë‘ ê¸°ì—… ë¹„êµ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±"""
    try:
        # ë‘ ê¸°ì—…ì˜ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
        corp_name1 = get_corp_name_from_dart(corp_code1)
        corp_name2 = get_corp_name_from_dart(corp_code2)
        
        # ë‘ ê¸°ì—…ì˜ ì¬ë¬´ì§€í‘œ ì¡°íšŒ
        indicators1 = get_company_financial_indicators(corp_code1, year, quarter)
        indicators2 = get_company_financial_indicators(corp_code2, year, quarter)
        
        # ë‘ ê¸°ì—…ì˜ ì£¼ìš”ê³„ì • ì¡°íšŒ
        accounts1 = get_company_major_accounts(corp_code1, year, quarter)
        accounts2 = get_company_major_accounts(corp_code2, year, quarter)
        
        # ê¸°ë³¸ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ (ê¸°ì¡´ í•¨ìˆ˜ í™œìš©)
        try:
            financial1 = _mcp_extract_summary_from_statements(corp_code1, year)
        except:
            financial1 = {}
            
        try:
            financial2 = _mcp_extract_summary_from_statements(corp_code2, year)
        except:
            financial2 = {}
        
        # ë¹„êµ ëŒ€ì‹œë³´ë“œ JSON êµ¬ì¡° ìƒì„±
        comparison_data = {
            'comparison_info': {
                'company1': {
                    'corp_code': corp_code1,
                    'corp_name': corp_name1
                },
                'company2': {
                    'corp_code': corp_code2,
                    'corp_name': corp_name2
                },
                'analysis_year': year,
                'report_type': quarter,
                'generated_at': datetime.now().isoformat()
            },
            
            # ê¸°ë³¸ ì¬ë¬´ ë¹„êµ (ê¸°ì¡´ ë¡œì§)
            'basic_financial_comparison': {
                'company1': {
                    'revenue': financial1.get('revenue', 0),
                    'operating_profit': financial1.get('operating_profit', 0),
                    'net_profit': financial1.get('net_profit', 0),
                    'total_assets': financial1.get('total_assets', 0),
                    'total_debt': financial1.get('total_debt', 0),
                    'total_equity': financial1.get('total_equity', 0)
                },
                'company2': {
                    'revenue': financial2.get('revenue', 0),
                    'operating_profit': financial2.get('operating_profit', 0),
                    'net_profit': financial2.get('net_profit', 0),
                    'total_assets': financial2.get('total_assets', 0),
                    'total_debt': financial2.get('total_debt', 0),
                    'total_equity': financial2.get('total_equity', 0)
                }
            },
            
            # ì¬ë¬´ì§€í‘œ ë¹„êµ
            'financial_indicators_comparison': {
                'profitability': {  # ìˆ˜ìµì„± ì§€í‘œ
                    'company1': indicators1.get('profitability', {}),
                    'company2': indicators2.get('profitability', {}),
                    'key_metrics': ['ì˜ì—…ì´ìµë¥ ', 'ìˆœì´ìµë¥ ', 'ROE', 'ROA']  # ì£¼ìš” ìˆ˜ìµì„± ì§€í‘œ
                },
                'stability': {  # ì•ˆì •ì„± ì§€í‘œ
                    'company1': indicators1.get('stability', {}),
                    'company2': indicators2.get('stability', {}),
                    'key_metrics': ['ë¶€ì±„ë¹„ìœ¨', 'ìœ ë™ë¹„ìœ¨', 'ë‹¹ì¢Œë¹„ìœ¨', 'ìê¸°ìë³¸ë¹„ìœ¨']  # ì£¼ìš” ì•ˆì •ì„± ì§€í‘œ
                },
                'growth': {  # ì„±ì¥ì„± ì§€í‘œ
                    'company1': indicators1.get('growth', {}),
                    'company2': indicators2.get('growth', {}),
                    'key_metrics': ['ë§¤ì¶œì•¡ì¦ê°€ìœ¨', 'ì˜ì—…ì´ìµì¦ê°€ìœ¨', 'ìˆœì´ìµì¦ê°€ìœ¨']  # ì£¼ìš” ì„±ì¥ì„± ì§€í‘œ
                },
                'activity': {  # í™œë™ì„± ì§€í‘œ
                    'company1': indicators1.get('activity', {}),
                    'company2': indicators2.get('activity', {}),
                    'key_metrics': ['ì´ìì‚°íšŒì „ìœ¨', 'ë§¤ì¶œì±„ê¶ŒíšŒì „ìœ¨', 'ì¬ê³ ìì‚°íšŒì „ìœ¨']  # ì£¼ìš” í™œë™ì„± ì§€í‘œ
                }
            },
            
            # ì£¼ìš” ê³„ì • ë¹„êµ
            'major_accounts_comparison': {
                'balance_sheet': {  # ì¬ë¬´ìƒíƒœí‘œ
                    'company1': accounts1.get('balance_sheet', {}),
                    'company2': accounts2.get('balance_sheet', {}),
                    'key_accounts': ['ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„', 'ìœ ë™ìì‚°', 'ë¹„ìœ ë™ìì‚°', 'ìœ ë™ë¶€ì±„', 'ë¹„ìœ ë™ë¶€ì±„']
                },
                'income_statement': {  # ì†ìµê³„ì‚°ì„œ
                    'company1': accounts1.get('income_statement', {}),
                    'company2': accounts2.get('income_statement', {}),
                    'key_accounts': ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ì˜ì—…ë¹„ìš©', 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„']
                }
            },
            
            # ë¹„êµ ìš”ì•½ (ìë™ ê³„ì‚°)
            'comparison_summary': {
                'revenue_comparison': {
                    'winner': corp_name1 if financial1.get('revenue', 0) > financial2.get('revenue', 0) else corp_name2,
                    'difference_rate': abs(financial1.get('revenue', 0) - financial2.get('revenue', 0)) / max(financial1.get('revenue', 1), financial2.get('revenue', 1)) * 100 if max(financial1.get('revenue', 1), financial2.get('revenue', 1)) > 0 else 0
                },
                'profitability_comparison': {
                    'winner': corp_name1 if financial1.get('net_profit', 0) > financial2.get('net_profit', 0) else corp_name2,
                    'difference_rate': abs(financial1.get('net_profit', 0) - financial2.get('net_profit', 0)) / max(abs(financial1.get('net_profit', 1)), abs(financial2.get('net_profit', 1))) * 100 if max(abs(financial1.get('net_profit', 1)), abs(financial2.get('net_profit', 1))) > 0 else 0
                },
                'asset_comparison': {
                    'winner': corp_name1 if financial1.get('total_assets', 0) > financial2.get('total_assets', 0) else corp_name2,
                    'difference_rate': abs(financial1.get('total_assets', 0) - financial2.get('total_assets', 0)) / max(financial1.get('total_assets', 1), financial2.get('total_assets', 1)) * 100 if max(financial1.get('total_assets', 1), financial2.get('total_assets', 1)) > 0 else 0
                }
            },
            
            # ì—…ê³„ í¬ì§€ì…˜ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
            'industry_position': {
                'company1_strengths': [],  # AI ë¶„ì„ìœ¼ë¡œ ì±„ìš¸ ìˆ˜ ìˆìŒ
                'company2_strengths': [],
                'comparison_notes': f"{corp_name1}ê³¼ {corp_name2}ì˜ {year}ë…„ ì¬ë¬´ ë¹„êµ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
            }
        }
        
        return comparison_data
        
    except Exception as e:
        print(f"ê¸°ì—… ë¹„êµ ëŒ€ì‹œë³´ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        raise

@app.route('/api/comparison', methods=['POST'])
def generate_comparison():
    """ë‘ ê¸°ì—… ë¹„êµ ëŒ€ì‹œë³´ë“œ API"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ['corp_code1', 'corp_code2']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'í•„ìˆ˜ ì •ë³´ ëˆ„ë½: {field}'}), 400
        
        corp_code1 = data['corp_code1']
        corp_code2 = data['corp_code2']
        year = data.get('year', '2023')
        quarter = data.get('quarter', '11011')  # ê¸°ë³¸ê°’: ì‚¬ì—…ë³´ê³ ì„œ
        
        # ë™ì¼í•œ ê¸°ì—… ë¹„êµ ë°©ì§€
        if corp_code1 == corp_code2:
            return jsonify({'error': 'ë™ì¼í•œ ê¸°ì—…ì€ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # ë¹„êµ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
        comparison_data = generate_comparison_dashboard(corp_code1, corp_code2, year, quarter)
        
        return jsonify({
            'status': 'success',
            'data': comparison_data
        })
        
    except Exception as e:
        logger.error(f"ê¸°ì—… ë¹„êµ API ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/comparison/indicators/<corp_code>', methods=['GET'])
def get_single_company_indicators(corp_code):
    """ë‹¨ì¼ ê¸°ì—…ì˜ ì¬ë¬´ì§€í‘œ ì¡°íšŒ (ë¹„êµ ì „ ë¯¸ë¦¬ë³´ê¸°ìš©)"""
    try:
        year = request.args.get('year', '2023')
        quarter = request.args.get('quarter', '11011')
        
        corp_name = get_corp_name_from_dart(corp_code)
        indicators = get_company_financial_indicators(corp_code, year, quarter)
        accounts = get_company_major_accounts(corp_code, year, quarter)
        
        return jsonify({
            'status': 'success',
            'data': {
                'corp_code': corp_code,
                'corp_name': corp_name,
                'year': year,
                'quarter': quarter,
                'indicators': indicators,
                'major_accounts': accounts
            }
        })
        
    except Exception as e:
        logger.error(f"ë‹¨ì¼ ê¸°ì—… ì§€í‘œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/long-term-analysis/<corp_code>', methods=['GET'])
def get_long_term_analysis(corp_code):
    """ì¥ê¸° ì¬ë¬´ ë¶„ì„ (10ë…„)"""
    try:
        period = int(request.args.get('period', '10'))
        
        if _MCP_SVC is None:
            return jsonify({'error': 'MCP ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 500
        
        # ì¥ê¸° ì‹œê³„ì—´ ë¶„ì„
        analysis_result = _MCP_SVC.analyze_time_series(corp_code, period)
        if not analysis_result.get('ok'):
            return jsonify({'error': analysis_result.get('error', 'ì¥ê¸° ë¶„ì„ ì‹¤íŒ¨')}), 500
        
        return jsonify(analysis_result.get('data', {}))
        
    except Exception as e:
        logger.error(f"ì¥ê¸° ì¬ë¬´ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/rim-valuation/<corp_code>', methods=['GET'])
def get_rim_valuation(corp_code):
    """RIM ê¸°ì—…ê°€ì¹˜ í‰ê°€"""
    try:
        year = request.args.get('year', '2023')
        industry = request.args.get('industry', 'ì œì¡°')
        
        if _MCP_SVC is None:
            return jsonify({'error': 'MCP ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 500
        
        # RIM ê°€ì¹˜ ê³„ì‚°
        rim_result = _MCP_SVC.calculate_rim_value(corp_code, year, industry)
        if not rim_result.get('ok'):
            return jsonify({'error': rim_result.get('error', 'RIM ê³„ì‚° ì‹¤íŒ¨')}), 500
        
        return jsonify(rim_result.get('data', {}))
        
    except Exception as e:
        logger.error(f"RIM ê°€ì¹˜ í‰ê°€ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/valuation-comparison/<corp_code>', methods=['GET'])
def get_valuation_comparison(corp_code):
    """ì ˆëŒ€ê°€ì¹˜ vs ìƒëŒ€ê°€ì¹˜ ë¹„êµ"""
    try:
        year = request.args.get('year', '2023')
        
        if _MCP_SVC is None:
            return jsonify({'error': 'MCP ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 500
        
        # ê°€ì¹˜í‰ê°€ ë¹„êµ
        comparison_result = _MCP_SVC.compare_valuation_methods(corp_code, year)
        if not comparison_result.get('ok'):
            return jsonify({'error': comparison_result.get('error', 'ê°€ì¹˜í‰ê°€ ë¹„êµ ì‹¤íŒ¨')}), 500
        
        return jsonify(comparison_result.get('data', {}))
        
    except Exception as e:
        logger.error(f"ê°€ì¹˜í‰ê°€ ë¹„êµ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/advanced-charts/<corp_code>', methods=['GET'])
def get_advanced_charts(corp_code):
    """ê³ ê¸‰ ì°¨íŠ¸ ë°ì´í„° (ì›Œí„°í´, ìŠ¤íŒŒì´ë”, íˆíŠ¸ë§µ)"""
    try:
        year = request.args.get('year', '2023')
        
        if _MCP_SVC is None:
            return jsonify({'error': 'MCP ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 500
        
        # ê³ ê¸‰ ì°¨íŠ¸ ë°ì´í„° ìƒì„±
        charts_result = _MCP_SVC.generate_advanced_chart_data(corp_code, year)
        if not charts_result.get('ok'):
            return jsonify({'error': charts_result.get('error', 'ê³ ê¸‰ ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì‹¤íŒ¨')}), 500
        
        return jsonify(charts_result.get('data', {}))
        
    except Exception as e:
        logger.error(f"ê³ ê¸‰ ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001, debug=True)