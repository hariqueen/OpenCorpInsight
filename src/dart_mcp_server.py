#!/usr/bin/env python3
"""
DART MCP Server - Open DART APIë¥¼ MCP ë„êµ¬ë¡œ ì œê³µí•˜ëŠ” ì„œë²„
"""

import asyncio
import json
import logging
import os
import sys
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import requests
import pandas as pd
import zipfile
import io
import xml.etree.ElementTree as ET

# AWS Secrets Manager (ì„ íƒ)
try:
    import boto3
    from botocore.exceptions import ClientError
    BOTO_AVAILABLE = True
except Exception:
    BOTO_AVAILABLE = False

from mcp.server import Server, NotificationOptions
from mcp.server.models import InitializationOptions
from mcp.server.stdio import stdio_server
from mcp.types import Tool
import mcp.types as types

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from cache_manager import cache_manager, cached_api_call
from news_analyzer import news_analyzer
from report_generator import report_generator
from portfolio_analyzer import portfolio_analyzer
from time_series_analyzer import time_series_analyzer
from benchmark_analyzer import benchmark_analyzer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("dart-mcp-server")

# ì „ì—­ ë³€ìˆ˜
API_KEY = None
CORP_CODE_CACHE = {}
# Perplexity API í‚¤ë„ í•¨ê»˜ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ì „ì—­ì— ë³´ê´€
PERPLEXITY_API_KEY = None

# ì£¼ìš” ê¸°ì—… ë§¤í•‘ í…Œì´ë¸” (ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´)
MAJOR_COMPANIES = {
    'ì‚¼ì„±ì „ì': 'ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬',
    'í˜„ëŒ€ìë™ì°¨': 'í˜„ëŒ€ìë™ì°¨ì£¼ì‹íšŒì‚¬', 
    'SKí•˜ì´ë‹‰ìŠ¤': 'SKí•˜ì´ë‹‰ìŠ¤ì£¼ì‹íšŒì‚¬',
    'LGì „ì': 'LGì „ìì£¼ì‹íšŒì‚¬',
    'NAVER': 'ë„¤ì´ë²„ì£¼ì‹íšŒì‚¬',
    'ì¹´ì¹´ì˜¤': 'ì£¼ì‹íšŒì‚¬ì¹´ì¹´ì˜¤',
    'í¬ìŠ¤ì½”': 'í¬ìŠ¤ì½”í™€ë”©ìŠ¤ì£¼ì‹íšŒì‚¬',
    'ì‚¼ì„±SDI': 'ì‚¼ì„±SDIì£¼ì‹íšŒì‚¬',
    'LGí™”í•™': 'LGí™”í•™ì£¼ì‹íšŒì‚¬',
    'í˜„ëŒ€ëª¨ë¹„ìŠ¤': 'í˜„ëŒ€ëª¨ë¹„ìŠ¤ì£¼ì‹íšŒì‚¬',
    'KBê¸ˆìœµ': 'KBê¸ˆìœµì§€ì£¼ì£¼ì‹íšŒì‚¬',
    'ì‹ í•œì§€ì£¼': 'ì‹ í•œì§€ì£¼ì£¼ì‹íšŒì‚¬',
    'SK': 'SKì£¼ì‹íšŒì‚¬',
    'LG': 'LGì£¼ì‹íšŒì‚¬'
}

# Secrets Manager â†’ .env â†’ í•˜ë“œì½”ë”©(ì„ì‹œ) ìˆœì„œë¡œ API í‚¤ ë¡œë“œ
try:
    from dotenv import load_dotenv
    from pathlib import Path

    # 1) AWS Secrets Manager ìš°ì„  ì‹œë„
    if BOTO_AVAILABLE:
        try:
            secret_name = os.getenv("DART_API_SECRET_NAME", "DART_API_KEY")
            region_name = os.getenv("AWS_REGION", "ap-northeast-2")
            session = boto3.session.Session()
            client = session.client(service_name='secretsmanager', region_name=region_name)
            get_secret_value_response = client.get_secret_value(SecretId=secret_name)
            secret_string = get_secret_value_response.get('SecretString')
            if secret_string:
                # í‚¤ë§Œ ì €ì¥ëœ ê²½ìš°ì™€ JSON ì €ì¥ëœ ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
                if secret_string.strip().startswith('{'):
                    import json as _json
                    _data = _json.loads(secret_string)
                    API_KEY = _data.get('DART_API_KEY') or _data.get('api_key') or _data.get('value')
                else:
                    API_KEY = secret_string
                if API_KEY:
                    logger.info("DART API í‚¤ë¥¼ AWS Secrets Managerì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤")
        except ClientError as e:
            logger.warning(f"AWS Secrets Managerì—ì„œ í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        except Exception as e:
            logger.warning(f"Secrets Manager ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {e}")

    # 2) .env ë¡œë“œ (Secretsì—ì„œ ëª» ì½ì—ˆê±°ë‚˜ ë³´ì¡° í‚¤ë“¤)
    possible_paths = [
        Path(__file__).parent.parent / ".env",
        Path.cwd() / ".env",
        Path("/Users/choetaeyeong/projects/OpenCorpInsight/.env")
    ]
    for env_file in possible_paths:
        if env_file.exists():
            load_dotenv(env_file, override=True)
            if not API_KEY:
                API_KEY = os.getenv('DART_API_KEY')
            if not PERPLEXITY_API_KEY:
                PERPLEXITY_API_KEY = os.getenv('PERPLEXITY_API_KEY')
            if API_KEY:
                logger.info(f"DART API í‚¤ ë¡œë“œë¨: {API_KEY[:10]}...")
                break

    # 3) ìµœí›„ ìˆ˜ë‹¨: í•˜ë“œì½”ë”©(ì„ì‹œ)
    if not API_KEY:
        logger.warning("API í‚¤ ë¡œë“œ ì‹¤íŒ¨ - ì„ì‹œ í•˜ë“œì½”ë”© í‚¤ ì‚¬ìš©")
        API_KEY = "4fde700d04b755c3dd2989a85b742aa35bf65062"
        logger.info(f"ì„ì‹œ DART API í‚¤ ì‚¬ìš©: {API_KEY[:10]}...")

except ImportError:
    logger.warning("python-dotenv ë¯¸ì„¤ì¹˜ - Secrets/.env ëŒ€ì‹  ì„ì‹œ í‚¤ ì‚¬ìš©")
    API_KEY = "4fde700d04b755c3dd2989a85b742aa35bf65062"
    PERPLEXITY_API_KEY = os.getenv('PERPLEXITY_API_KEY')

# MCP ì„œë²„ ìƒì„± ë° ì´ˆê¸°í™”
app = Server("OpenCorpInsight")

# Perplexity MCP ê²€ìƒ‰ í•¨ìˆ˜ (ì‹¤ì œ API í˜¸ì¶œ)
async def perplexity_search_wrapper(query: str, recency_filter: Optional[str] = None):
    """Perplexity APIë¥¼ í†µí•´ JSON ë‰´ìŠ¤ ëª©ë¡ì„ ë°›ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜ í˜•ì‹: {"articles": [{"title":...,"content":...,"url":...,"source":...,"published_date":"YYYY-MM-DD"}, ...]}
    """
    try:
        if not PERPLEXITY_API_KEY:
            logger.warning("PERPLEXITY_API_KEY ë¯¸ì„¤ì • - Mockìœ¼ë¡œ ëŒ€ì²´ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            return {"articles": []}
        period_map = {'day': 'ì§€ë‚œ 24ì‹œê°„', 'week': 'ì§€ë‚œ 7ì¼', 'month': 'ì§€ë‚œ 30ì¼'}
        period_text = period_map.get(recency_filter or '', 'ìµœê·¼')

        api_url = "https://api.perplexity.ai/chat/completions"
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "X-API-Key": PERPLEXITY_API_KEY,
            "Content-Type": "application/json"
        }
        prompt = (
            "ì•„ë˜ ì§ˆì˜ì— ëŒ€í•´ í•œêµ­ì–´ ë‰´ìŠ¤ 10ê±´ì„ JSON ê°ì²´ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”. í‚¤ëŠ” 'articles'ì´ë©°, ê° í•­ëª©ì€ "
            "{title, content, url, source, published_date(YYYY-MM-DD)} í•„ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì¶”ê°€ ì„¤ëª…/ì„œë¬¸ ê¸ˆì§€.\n"
            f"ì§ˆì˜: {query} ê´€ë ¨ {period_text} ìµœì‹  ë‰´ìŠ¤"
        )
        body = {
            "model": "sonar-small-online",
            "messages": [
                {"role": "system", "content": "ë„ˆëŠ” ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°ì´ë‹¤. ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•œë‹¤."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 800,
            "temperature": 0.2,
            "response_format": {"type": "json_object"}
        }
        resp = requests.post(api_url, headers=headers, json=body, timeout=30)
        if resp.status_code != 200:
            logger.warning(f"Perplexity API í˜¸ì¶œ ì‹¤íŒ¨: {resp.status_code} {resp.text[:200]}")
            return {"articles": []}
        data = resp.json()
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "{}")
        try:
            parsed = json.loads(content)
            if isinstance(parsed, dict) and 'articles' in parsed:
                return parsed
        except Exception:
            pass
        return {"articles": []}
    except Exception as e:
        logger.error(f"Perplexity ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {"articles": []}

# ë‰´ìŠ¤ ë¶„ì„ê¸°ì— Perplexity ê²€ìƒ‰ í•¨ìˆ˜ ì—°ê²° (Mock ë°©ì§€)
try:
    news_analyzer.set_perplexity_search_function(perplexity_search_wrapper)
    logger.info("ë‰´ìŠ¤ ë¶„ì„ê¸°ì— Perplexity ê²€ìƒ‰ í•¨ìˆ˜ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤")
except Exception as _e:
    logger.warning("Perplexity ê²€ìƒ‰ í•¨ìˆ˜ ì—°ê²° ì‹¤íŒ¨ (ë‰´ìŠ¤ ê¸°ëŠ¥ì´ Mockìœ¼ë¡œ ë™ì‘í•  ìˆ˜ ìˆìŒ)")

async def get_corp_code(corp_name: str) -> str:
    """ê¸°ì—… ê³ ìœ ë²ˆí˜¸ ì¡°íšŒ"""
    # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
    logger.info(f"get_corp_code í˜¸ì¶œë¨ - corp_name: {corp_name}")
    logger.info(f"í˜„ì¬ API_KEY ìƒíƒœ: {API_KEY[:10] if API_KEY else 'None'}...")
    logger.info(f"API_KEY íƒ€ì…: {type(API_KEY)}")
    
    if not API_KEY:
        raise ValueError("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    if corp_name in CORP_CODE_CACHE:
        return CORP_CODE_CACHE[corp_name]
    
    # ì£¼ìš” ê¸°ì—… ë§¤í•‘ í™•ì¸
    search_name = MAJOR_COMPANIES.get(corp_name, corp_name)
    if search_name != corp_name:
        logger.info(f"ì£¼ìš” ê¸°ì—… ë§¤í•‘ ì‚¬ìš©: {corp_name} -> {search_name}")
        # ë§¤í•‘ëœ ì´ë¦„ë„ ìºì‹œì—ì„œ í™•ì¸
        if search_name in CORP_CODE_CACHE:
            CORP_CODE_CACHE[corp_name] = CORP_CODE_CACHE[search_name]
            return CORP_CODE_CACHE[search_name]
    
    # corpCode API í˜¸ì¶œ
    zip_url = f'https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={API_KEY}'
    zip_bytes = requests.get(zip_url).content
    
    with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:
        corp_bytes = zf.read('CORPCODE.xml')
        try:
            xml_str = corp_bytes.decode('euc-kr')
        except UnicodeDecodeError:
            xml_str = corp_bytes.decode('utf-8')
    
    root = ET.fromstring(xml_str)
    
    # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•œ í›„ë³´ ëª©ë¡
    exact_matches = []
    partial_matches = []
    
    for item in root.findall('.//list'):
        name = item.find('corp_name').text
        code = item.find('corp_code').text
        
        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„  (ì›ë˜ ì´ë¦„ê³¼ ë§¤í•‘ëœ ì´ë¦„ ëª¨ë‘ í™•ì¸)
        if (name == corp_name or name == search_name or 
            name == corp_name + "ì£¼ì‹íšŒì‚¬" or name == "ì£¼ì‹íšŒì‚¬" + corp_name or
            name == search_name + "ì£¼ì‹íšŒì‚¬" or name == "ì£¼ì‹íšŒì‚¬" + search_name):
            exact_matches.append((name, code))
        # ë¶€ë¶„ ë§¤ì¹­ (ì›ë˜ ì´ë¦„ê³¼ ë§¤í•‘ëœ ì´ë¦„ ëª¨ë‘ í™•ì¸)
        elif corp_name in name or search_name in name:
            partial_matches.append((name, code))
    
    # ì •í™•í•œ ë§¤ì¹­ì´ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
    if exact_matches:
        # ê°€ì¥ ì§§ì€ ì´ë¦„ ì„ íƒ (ë³¸ì‚¬ ìš°ì„ )
        best_match = min(exact_matches, key=lambda x: len(x[0]))
        CORP_CODE_CACHE[corp_name] = best_match[1]
        logger.info(f"ì •í™•í•œ ë§¤ì¹­ ë°œê²¬: {corp_name} -> {best_match[0]} ({best_match[1]})")
        return best_match[1]
    
    # ë¶€ë¶„ ë§¤ì¹­ì—ì„œ ê°€ì¥ ì í•©í•œ ê²ƒ ì„ íƒ
    if partial_matches:
        # íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²ƒ ì œì™¸ (ì„œë¹„ìŠ¤, ì¨ë¹„ìŠ¤, ìíšŒì‚¬ ë“±)
        filtered_matches = []
        exclude_keywords = ['ì„œë¹„ìŠ¤', 'ì¨ë¹„ìŠ¤', 'ì¼€ì´', 'CS', 'ì”¨ì—ìŠ¤', 'ì—ìŠ¤']
        
        for name, code in partial_matches:
            if not any(keyword in name for keyword in exclude_keywords):
                filtered_matches.append((name, code))
        
        if filtered_matches:
            # ê°€ì¥ ì§§ì€ ì´ë¦„ ì„ íƒ (ë³¸ì‚¬ ìš°ì„ )
            best_match = min(filtered_matches, key=lambda x: len(x[0]))
            CORP_CODE_CACHE[corp_name] = best_match[1]
            logger.info(f"í•„í„°ë§ëœ ë§¤ì¹­ ë°œê²¬: {corp_name} -> {best_match[0]} ({best_match[1]})")
            return best_match[1]
        else:
            # í•„í„°ë§ í›„ì—ë„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë˜ ë¶€ë¶„ ë§¤ì¹­ ì‚¬ìš©
            best_match = min(partial_matches, key=lambda x: len(x[0]))
            CORP_CODE_CACHE[corp_name] = best_match[1]
            logger.warning(f"ë¶€ë¶„ ë§¤ì¹­ ì‚¬ìš©: {corp_name} -> {best_match[0]} ({best_match[1]})")
            return best_match[1]
    
    raise ValueError(f"ê¸°ì—… '{corp_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# API í‚¤ ì„¤ì • í•¨ìˆ˜
async def set_dart_api_key(api_key: str) -> List[types.TextContent]:
    """DART API í‚¤ ì„¤ì •"""
    global API_KEY
    API_KEY = api_key
    logger.info(f"API í‚¤ ì„¤ì •ë¨: {API_KEY[:10]}...")
    return [types.TextContent(type="text", text=f"âœ… DART API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {api_key[:10]}...")]

# ê¸°ì—… ì •ë³´ ì¡°íšŒ
async def get_company_info(corp_name: str) -> List[types.TextContent]:
    """ê¸°ì—… ì •ë³´ ì¡°íšŒ"""
    try:
        corp_code = await get_corp_code(corp_name)
        
        url = 'https://opendart.fss.or.kr/api/company.json'
        params = {
            'crtfc_key': API_KEY,
            'corp_code': corp_code
        }
        
        response = requests.get(url, params=params)
        data = response.json()
        
        if data['status'] != '000':
            return [types.TextContent(type="text", text=f"ì˜¤ë¥˜: {data['message']}")]
        
        info = data
        result = f"""
## {corp_name} ê¸°ì—… ì •ë³´

- **íšŒì‚¬ëª…**: {info.get('corp_name', 'N/A')}
- **ëŒ€í‘œìëª…**: {info.get('ceo_nm', 'N/A')}
- **ì„¤ë¦½ì¼**: {info.get('est_dt', 'N/A')}
- **ì£¼ì†Œ**: {info.get('adres', 'N/A')}
- **í™ˆí˜ì´ì§€**: {info.get('hm_url', 'N/A')}
- **ì—…ì¢…**: {info.get('bizr_no', 'N/A')}
"""
        
        return [types.TextContent(type="text", text=result)]
        
    except Exception as e:
        return [types.TextContent(type="text", text=f"ê¸°ì—… ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¬ë¬´ì œí‘œ ì¡°íšŒ
async def get_financial_statements(corp_name: str, bsns_year: str, reprt_code: str, fs_div: str, statement_type: str) -> List[types.TextContent]:
    """ì¬ë¬´ì œí‘œ ì¡°íšŒ"""
    try:
        corp_code = await get_corp_code(corp_name)
        logger.info(f"ì¬ë¬´ì œí‘œ ì¡°íšŒ ì‹œì‘: {corp_name} ({corp_code}) - {bsns_year}ë…„ {statement_type}")
        
        # ì—¬ëŸ¬ ë³´ê³ ì„œ ì½”ë“œì™€ ì¬ë¬´ì œí‘œ êµ¬ë¶„ì„ ì‹œë„
        report_codes = [reprt_code, '11014', '11013', '11012', '11011']  # ì‚¬ì—…ë³´ê³ ì„œ, 3ë¶„ê¸°, ë°˜ê¸°, 1ë¶„ê¸°
        fs_divisions = [fs_div, 'CFS', 'OFS']  # ì—°ê²°, ë³„ë„
        
        best_result = None
        attempted_combinations = []
        
        for rcode in report_codes:
            for fsdiv in fs_divisions:
                try:
                    url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
                    params = {
                        'crtfc_key': API_KEY,
                        'corp_code': corp_code,
                        'bsns_year': bsns_year,
                        'reprt_code': rcode,
                        'fs_div': fsdiv
                    }
                    
                    attempted_combinations.append(f"{rcode}-{fsdiv}")
                    logger.info(f"ì‹œë„ ì¤‘: {rcode} ({_get_report_name(rcode)}) - {fsdiv}")
                    
                    response = requests.get(url, params=params)
                    data = response.json()
                    
                    if data['status'] == '000' and 'list' in data:
                        df = pd.DataFrame(data['list'])
                        
                        # ìš”ì²­í•œ ì¬ë¬´ì œí‘œ íƒ€ì… ì°¾ê¸°
                        statement_df = df[df['sj_nm'] == statement_type].copy()
                        
                        if not statement_df.empty:
                            # ì„±ê³µì ìœ¼ë¡œ ë°ì´í„° ë°œê²¬
                            amount_cols = [c for c in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount'] if c in statement_df.columns]
                            
                            if amount_cols:
                                result_df = statement_df[['account_nm', *amount_cols]].rename(columns={
                                    'account_nm': 'ê³„ì •',
                                    'thstrm_amount': 'ë‹¹ê¸°',
                                    'frmtrm_amount': 'ì „ê¸°',
                                    'bfefrmtrm_amount': 'ì „ì „ê¸°'
                                })
                                
                                report_name = _get_report_name(rcode)
                                fs_name = "ì—°ê²°" if fsdiv == "CFS" else "ë³„ë„"
                                
                                result = f"""
## {corp_name} {bsns_year}ë…„ {statement_type} ({report_name}, {fs_name})

{result_df.to_string(index=False)}

ğŸ“Š **ë°ì´í„° ì •ë³´**
- ë³´ê³ ì„œ: {report_name} ({rcode})
- ì¬ë¬´ì œí‘œ: {fs_name} ({fsdiv})
- í•­ëª© ìˆ˜: {len(result_df)}ê°œ
"""
                                
                                logger.info(f"ì¬ë¬´ì œí‘œ ì¡°íšŒ ì„±ê³µ: {rcode}-{fsdiv}, {len(result_df)}ê°œ í•­ëª©")
                                return [types.TextContent(type="text", text=result)]
                        
                        # ë‹¤ë¥¸ ì¬ë¬´ì œí‘œ íƒ€ì…ë“¤ë„ í™•ì¸
                        available_statements = df['sj_nm'].unique().tolist()
                        if available_statements and not best_result:
                            best_result = {
                                'corp_name': corp_name,
                                'year': bsns_year,
                                'report_code': rcode,
                                'fs_div': fsdiv,
                                'available_statements': available_statements,
                                'total_records': len(df)
                            }
                    
                except Exception as e:
                    logger.warning(f"ì¡°íšŒ ì‹¤íŒ¨ ({rcode}-{fsdiv}): {e}")
                    continue
        
        # ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
        if best_result:
            result = f"""
## {corp_name} {bsns_year}ë…„ ì¬ë¬´ì œí‘œ ì¡°íšŒ ê²°ê³¼

âŒ **ìš”ì²­í•œ ì¬ë¬´ì œí‘œ ì—†ìŒ**: {statement_type}

âœ… **ì‚¬ìš© ê°€ëŠ¥í•œ ì¬ë¬´ì œí‘œ**:
{chr(10).join([f"- {stmt}" for stmt in best_result['available_statements']])}

ğŸ“‹ **ì¡°íšŒ ì •ë³´**:
- ë³´ê³ ì„œ: {_get_report_name(best_result['report_code'])}
- ì¬ë¬´ì œí‘œ êµ¬ë¶„: {"ì—°ê²°" if best_result['fs_div'] == "CFS" else "ë³„ë„"}
- ì´ ë°ì´í„° ìˆ˜: {best_result['total_records']}ê°œ

ğŸ’¡ **ì œì•ˆ**: ìœ„ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ì¬ë¬´ì œí‘œ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì„œ ë‹¤ì‹œ ì¡°íšŒí•´ë³´ì„¸ìš”.
"""
        else:
            result = f"""
## {corp_name} {bsns_year}ë…„ ì¬ë¬´ì œí‘œ ì¡°íšŒ ì‹¤íŒ¨

âŒ **ë°ì´í„° ì—†ìŒ**: í•´ë‹¹ ê¸°ì—…ì˜ {bsns_year}ë…„ ì¬ë¬´ì œí‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ” **ì‹œë„í•œ ì¡°í•©**: {', '.join(attempted_combinations)}

ğŸ’¡ **ê°€ëŠ¥í•œ ì›ì¸**:
- í•´ë‹¹ ì—°ë„ì˜ ê³µì‹œ ë°ì´í„°ê°€ ì•„ì§ ë“±ë¡ë˜ì§€ ì•ŠìŒ
- ê¸°ì—…ì´ í•´ë‹¹ ì—°ë„ì— ê³µì‹œ ì˜ë¬´ê°€ ì—†ì—ˆìŒ
- ë‹¤ë¥¸ ì—°ë„ (ì˜ˆ: {int(bsns_year)-1}ë…„, {int(bsns_year)-2}ë…„)ì˜ ë°ì´í„°ëŠ” ìˆì„ ìˆ˜ ìˆìŒ

ğŸ”„ **ëŒ€ì•ˆ**: ë‹¤ë¥¸ ì—°ë„ë¡œ ì¡°íšŒí•˜ê±°ë‚˜ DART ì „ìê³µì‹œì‹œìŠ¤í…œì—ì„œ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”.
"""
        
        return [types.TextContent(type="text", text=result)]
        
    except Exception as e:
        return [types.TextContent(type="text", text=f"ì¬ë¬´ì œí‘œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°
async def get_financial_ratios(corp_name: str, bsns_year: str, ratio_categories: List[str], include_industry_avg: bool) -> List[types.TextContent]:
    """ì¬ë¬´ë¹„ìœ¨ ê³„ì‚° ë° ì¡°íšŒ (ROE, ROA, ë¶€ì±„ë¹„ìœ¨, ìœ ë™ë¹„ìœ¨ ë“±)
    - ê³„ì •ëª…/í‘œ ì–‘ì‹ í¸ì°¨ë¥¼ ê³ ë ¤í•´ ë‹¤ì¤‘ íŒ¨í„´ ë° í¬ê´„ì†ìµê³„ì‚°ì„œê¹Œì§€ íƒìƒ‰
    - (1,234) í˜•ì‹ ìŒìˆ˜ ì²˜ë¦¬, '-' ë¬´ì‹œ ì²˜ë¦¬
    - ì—°ê°„ ë³´ê³ ì„œ(CFS) ê¸°ì¤€, í•„ìš” ì‹œ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ ë³´ì¡° ì¡°íšŒ
    """
    try:
        corp_code = await get_corp_code(corp_name)

        def parse_amount(val: str) -> float:
            if not val or val == '-':
                return 0.0
            s = str(val).replace(',', '').strip()
            neg = s.startswith('(') and s.endswith(')')
            if neg:
                s = s[1:-1]
            try:
                num = float(s)
            except Exception:
                return 0.0
            return -num if neg else num

        def fetch_df(reprt_code: str, fs_div: str) -> pd.DataFrame:
            url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
            params = {
                'crtfc_key': API_KEY,
                'corp_code': corp_code,
                'bsns_year': bsns_year,
                'reprt_code': reprt_code,
                'fs_div': fs_div,
            }
            resp = requests.get(url, params=params)
            j = resp.json()
            if j.get('status') != '000':
                return pd.DataFrame()
            return pd.DataFrame(j.get('list', []))

        # ìš°ì„  ì¡°í•©ë“¤: ì—°ê°„/ì—°ê²° â†’ ì—°ê°„/ë³„ë„ â†’ 3ë¶„ê¸°/ì—°ê²°
        tried: List[tuple[str, str]] = [('11014', 'CFS'), ('11014', 'OFS'), ('11013', 'CFS')]
        df = pd.DataFrame()
        for rc, fd in tried:
            df = fetch_df(rc, fd)
            if not df.empty:
                break
        if df.empty:
            return [types.TextContent(type='text', text='ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì—°ë„/ë³´ê³ ì„œ ì½”ë“œë¥¼ ë³€ê²½í•´ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')]

        def get_value(sj_candidates: List[str], account_patterns: List[str]) -> float:
            target = df[df['sj_nm'].isin(sj_candidates)] if 'sj_nm' in df.columns else df
            if target.empty:
                return 0.0
            for pattern in account_patterns:
                try:
                    m = target[target['account_nm'].str.contains(pattern, na=False, regex=True)]
                except Exception:
                    continue
                if not m.empty:
                    # thstrm ìš°ì„ , ì—†ìœ¼ë©´ ê³¼ê±° í•­ëª© ë³´ì¡° ì¡°íšŒ
                    for col in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount']:
                        if col in m.columns:
                            val = m.iloc[0][col]
                            amt = parse_amount(val)
                            if amt != 0.0:
                                return amt
            return 0.0

        # ê³„ì • ì¶”ì¶œ
        total_assets = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìì‚°ì´ê³„'])
        total_equity = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìë³¸ì´ê³„'])
        total_liabilities = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ë¶€ì±„ì´ê³„'])
        current_assets = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìœ ë™ìì‚°'])
        current_liabilities = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìœ ë™ë¶€ì±„'])

        revenue = get_value(['ì†ìµê³„ì‚°ì„œ', 'í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë§¤ì¶œì•¡', 'ìˆ˜ìµ\(ë§¤ì¶œì•¡\)', 'ì˜ì—…ìˆ˜ìµ'])
        operating_profit = get_value(['ì†ìµê³„ì‚°ì„œ', 'í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ì˜ì—…ì´ìµ'])
        net_profit = get_value(['ì†ìµê³„ì‚°ì„œ', 'í¬ê´„ì†ìµê³„ì‚°ì„œ'], [
            'ë‹¹ê¸°ìˆœì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ\(ì†ì‹¤\)', 'ì§€ë°°ì£¼ì£¼ì§€ë¶„\s*ìˆœì´ìµ', 'ì§€ë°°ê¸°ì—…\s*ì†Œìœ ì£¼ì§€ë¶„\s*ìˆœì´ìµ', 'ì—°ê²°ë‹¹ê¸°ìˆœì´ìµ'
        ])

        ratios: Dict[str, Dict[str, float]] = {}
        if 'profitability' in ratio_categories:
            ratios['profitability'] = {}
            if total_equity > 0 and net_profit != 0:
                ratios['profitability']['ROE'] = round((net_profit / total_equity) * 100, 2)
            if total_assets > 0 and net_profit != 0:
                ratios['profitability']['ROA'] = round((net_profit / total_assets) * 100, 2)
            if revenue > 0:
                ratios['profitability']['ì˜ì—…ì´ìµë¥ '] = round((operating_profit / revenue) * 100, 2)
                if net_profit != 0:
                    ratios['profitability']['ìˆœì´ìµë¥ '] = round((net_profit / revenue) * 100, 2)
        if 'stability' in ratio_categories:
            ratios['stability'] = {}
            if total_equity > 0 and total_liabilities >= 0:
                ratios['stability']['ë¶€ì±„ë¹„ìœ¨'] = round((total_liabilities / total_equity) * 100, 2)
            if current_liabilities > 0:
                ratios['stability']['ìœ ë™ë¹„ìœ¨'] = round((current_assets / current_liabilities) * 100, 2)
            if total_assets > 0 and total_equity >= 0:
                ratios['stability']['ìê¸°ìë³¸ë¹„ìœ¨'] = round((total_equity / total_assets) * 100, 2)
        if 'activity' in ratio_categories and total_assets > 0 and revenue > 0:
            ratios.setdefault('activity', {})['ì´ìì‚°íšŒì „ìœ¨'] = round(revenue / total_assets, 2)

        # ê²°ê³¼ êµ¬ì„±
        result = f"## {corp_name} {bsns_year}ë…„ ì¬ë¬´ë¹„ìœ¨ ë¶„ì„\n\n"
        names = {'profitability': 'ìˆ˜ìµì„± ì§€í‘œ', 'stability': 'ì•ˆì •ì„± ì§€í‘œ', 'activity': 'í™œë™ì„± ì§€í‘œ', 'growth': 'ì„±ì¥ì„± ì§€í‘œ'}
        for cat, vals in ratios.items():
            result += f"### {names.get(cat, cat)}\n\n"
            for k, v in vals.items():
                suffix = '%' if k not in ['ì´ìì‚°íšŒì „ìœ¨'] else ''
                result += f"- **{k}**: {v}{suffix}\n"
            result += "\n"
        if not ratios:
            result += "- ìœ íš¨í•œ ì§€í‘œë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—°ë„/ë³´ê³ ì„œ ì½”ë“œë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì¬ë¬´ì œí‘œ êµ¬ë¶„ì„ ì‹œë„í•´ ì£¼ì„¸ìš”.\n"
        return [types.TextContent(type='text', text=result)]
    except Exception as e:
        return [types.TextContent(type='text', text=f"ì¬ë¬´ë¹„ìœ¨ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ì‹œê³„ì—´ ë¶„ì„ (ë˜í¼)
async def analyze_time_series(corp_name: str, analysis_period: int, metrics: List[str], forecast_periods: int) -> List[types.TextContent]:
    """ê¸°ì—…ì˜ ì¬ë¬´ ì„±ê³¼ ì‹œê³„ì—´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ì²« í˜¸ì¶œì—ì„œ ì‹¤ì œ DART ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ ìˆ˜ì§‘í•˜ì—¬ ì‚¬ìš©(ì—°ê°„ ë³´ê³ ì„œ ê¸°ì¤€)
    - ë§¤ì¶œì•¡/ì˜ì—…ì´ìµ/ìˆœì´ìµì„ ìµœê·¼ Në…„ ìˆ˜ì§‘, ëˆ„ë½ ë…„ë„ëŠ” ê±´ë„ˆëœ€
    """
    try:
        if not API_KEY:
            return [types.TextContent(type='text', text='âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.')]

        corp_code = await get_corp_code(corp_name)
        # ìµœê·¼ analysis_periodë…„ (ì˜¬í•´-1 ê¸°ì¤€) ì—­ì‚° ìˆ˜ì§‘
        end_year = datetime.now().year - 1
        years = list(range(end_year - analysis_period + 1, end_year + 1))

        def parse_amount(val: str) -> float:
            if not val or val == '-':
                return 0.0
            s = str(val).replace(',', '').strip()
            neg = s.startswith('(') and s.endswith(')')
            if neg:
                s = s[1:-1]
            try:
                num = float(s)
            except Exception:
                return 0.0
            return -num if neg else num

        def fetch_year(year: int) -> dict:
            url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
            params = {'crtfc_key': API_KEY,'corp_code': corp_code,'bsns_year': str(year),'reprt_code': '11014','fs_div': 'CFS'}
            j = requests.get(url, params=params).json()
            if j.get('status') != '000':
                return {}
            df = pd.DataFrame(j.get('list', []))
            if df.empty:
                return {}
            def get_value(sj_candidates, patterns):
                target = df[df['sj_nm'].isin(sj_candidates)] if 'sj_nm' in df.columns else df
                for pattern in patterns:
                    try:
                        m = target[target['account_nm'].str.contains(pattern, na=False, regex=True)]
                    except Exception:
                        m = pd.DataFrame()
                    if not m.empty:
                        for col in ['thstrm_amount','frmtrm_amount','bfefrmtrm_amount']:
                            if col in m.columns:
                                amt = parse_amount(m.iloc[0][col])
                                if amt != 0.0:
                                    return amt
                if 'account_id' in target.columns:
                    for pid in ['Revenue','Sales','OperatingIncome','ProfitLoss','NetIncome', 'ProfitLossAttributableToOwnersOfParent']:
                        m2 = target[target['account_id'].str.contains(pid, na=False)]
                        if not m2.empty:
                            for col in ['thstrm_amount','frmtrm_amount','bfefrmtrm_amount']:
                                if col in m2.columns:
                                    amt = parse_amount(m2.iloc[0][col])
                                    if amt != 0.0:
                                        return amt
                return 0.0
            revenue = get_value(['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë§¤ì¶œì•¡','ìˆ˜ìµ\(ë§¤ì¶œì•¡\)','ì˜ì—…ìˆ˜ìµ'])
            operating = get_value(['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ì˜ì—…ì´ìµ'])
            net = get_value(['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë‹¹ê¸°ìˆœì´ìµ','ë‹¹ê¸°ìˆœì´ìµ\(ì†ì‹¤\)','ì§€ë°°ì£¼ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì§€ë°°ê¸°ì—…\s*ì†Œìœ ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì—°ê²°ë‹¹ê¸°ìˆœì´ìµ'])
            return {'year': year, 'ë§¤ì¶œì•¡': revenue, 'ì˜ì—…ì´ìµ': operating, 'ìˆœì´ìµ': net}

        collected = [fetch_year(y) for y in years]
        collected = [c for c in collected if c]
        if not collected:
            return [types.TextContent(type='text', text='ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ê°„ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')]

        dates = [f"{c['year']}-12-31" for c in collected]
        financial_data = {
            'dates': dates,
            'ë§¤ì¶œì•¡': [c['ë§¤ì¶œì•¡'] for c in collected],
            'ì˜ì—…ì´ìµ': [c['ì˜ì—…ì´ìµ'] for c in collected],
            'ìˆœì´ìµ': [c['ìˆœì´ìµ'] for c in collected],
        }

        trend_result = await time_series_analyzer.analyze_financial_trends(corp_name, financial_data, len(collected), metrics)
        forecast_result = await time_series_analyzer.forecast_performance(corp_name, financial_data, forecast_periods, metrics)

        text = f"""# ğŸ“ˆ {corp_name} ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ë¶„ì„ ê¸°ê°„**: {len(collected)}ë…„ (ì—°ê°„)
- **ë¶„ì„ ì§€í‘œ**: {', '.join(metrics)}
- **ë°ì´í„° í¬ì¸íŠ¸**: {trend_result.get('data_points', 0)}ê°œ
- **ì˜ˆì¸¡ ê¸°ê°„**: {forecast_periods}ë¶„ê¸°
"""
        for metric, analysis in (trend_result.get('trend_results', {}) or {}).items():
            basic = analysis.get('basic_stats', {})
            trend = analysis.get('trend_analysis', {})
            text += f"\n### {metric}\n- **í‰ê· ê°’**: {basic.get('mean', 0):,.1f}\n- **ì„±ì¥ë¥  (CAGR)**: {basic.get('growth_rate', {}).get('cagr', 0):.1f}%\n- **íŠ¸ë Œë“œ ë°©í–¥**: {trend.get('direction', 'N/A')}\n- **íŠ¸ë Œë“œ ê°•ë„**: {trend.get('strength', 0):.2f}\n"
        return [types.TextContent(type='text', text=text)]
    except Exception as e:
        logger.error(f"ì‹œê³„ì—´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return [types.TextContent(type='text', text=f"âŒ ì‹œê³„ì—´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ (ë˜í¼)
async def compare_with_industry(corp_name: str, industry: str, comparison_metrics: List[str], analysis_type: str) -> List[types.TextContent]:
    """ê¸°ì—…ì„ ë™ì¢… ì—…ê³„ì™€ ë²¤ì¹˜ë§ˆí¬ ë¹„êµí•©ë‹ˆë‹¤"""
    try:
        if not API_KEY:
            return [types.TextContent(type='text', text='âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.')]
        benchmark_result = await benchmark_analyzer.compare_with_industry(corp_name, industry, comparison_metrics)
        text = f"""# ğŸ† {corp_name} ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ

## ğŸ“Š ë¹„êµ ê°œìš”
- **ì—…ì¢…**: {industry}
- **ë¹„êµ ì§€í‘œ**: {', '.join(comparison_metrics)}
- **ë¶„ì„ ìœ í˜•**: {analysis_type.title()}

## ğŸ“‹ ì§€í‘œë³„ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
"""
        for metric, result in (benchmark_result.get('benchmark_results', {}) or {}).items():
            text += f"\n### {metric}\n- **ê¸°ì—… ê°’**: {result.get('company_value', 0):.1f}\n- **ì—…ê³„ í‰ê· **: {result.get('industry_mean', 0):.1f}\n- **ì—…ê³„ ëŒ€ë¹„**: {result.get('vs_mean_pct', 0):+.1f}%\n- **ë°±ë¶„ìœ„**: {result.get('percentile', 0):.1f}% (ìƒìœ„)\n- **í‰ê°€**: {result.get('performance', 'N/A')}\n"
        return [types.TextContent(type='text', text=text)]
    except Exception as e:
        logger.error(f"ë²¤ì¹˜ë§ˆí¬ ë¹„êµ ì¤‘ ì˜¤ë¥˜: {e}")
        return [types.TextContent(type='text', text=f"âŒ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ê³µì‹œ ëª©ë¡ ì¡°íšŒ
async def get_disclosure_list(corp_name: str, bgn_de: str, end_de: str, page_count: int) -> List[types.TextContent]:
    """ê³µì‹œ ëª©ë¡ ì¡°íšŒ"""
    try:
        corp_code = await get_corp_code(corp_name)
        url = 'https://opendart.fss.or.kr/api/list.json'
        params = {
            'crtfc_key': API_KEY,
            'corp_code': corp_code,
            'bgn_de': bgn_de,
            'end_de': end_de,
            'page_count': page_count,
        }
        response = requests.get(url, params=params)
        data = response.json()
        if data.get('status') != '000':
            return [types.TextContent(type="text", text=f"ì˜¤ë¥˜: {data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")]
        disclosures = data.get('list', [])
        result = f"## {corp_name} ê³µì‹œ ëª©ë¡ ({bgn_de} ~ {end_de})\n\n"
        for disclosure in disclosures:
            result += f"- **{disclosure.get('report_nm','')}** ({disclosure.get('rcept_dt','')})\n"
            result += f"  - ì ‘ìˆ˜ë²ˆí˜¸: {disclosure.get('rcept_no','')}\n"
            result += f"  - ì œì¶œì¸: {disclosure.get('flr_nm','')}\n\n"
        return [types.TextContent(type="text", text=result)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"ê³µì‹œ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ê¸°ì—… ê°„ ì¬ë¬´ì§€í‘œ ë¹„êµ
async def compare_financials(companies: List[str], bsns_year: str, comparison_metrics: List[str], visualization: bool = True) -> List[types.TextContent]:
    """ì—¬ëŸ¬ ê¸°ì—…ì˜ ì¬ë¬´ì§€í‘œë¥¼ ë¹„êµ
    - í•œê¸€/ì˜ë¬¸ ì§€í‘œëª…ì„ ëª¨ë‘ í—ˆìš©í•˜ê³  ë‚´ë¶€ í‘œì¤€ í‚¤ë¡œ ì •ê·œí™”
    - ë‹¤ì¤‘ ë³´ê³ ì„œ ì¡°í•© ë° í¬ê´„ì†ìµê³„ì‚°ì„œê¹Œì§€ íƒìƒ‰í•˜ì—¬ ëˆ„ë½ ìµœì†Œí™”
    """
    try:
        # 1) ì§€í‘œ ì •ê·œí™”
        metric_alias = {
            'ë§¤ì¶œì•¡': 'revenue', 'revenue': 'revenue',
            'ì˜ì—…ì´ìµ': 'operating_profit', 'operating_profit': 'operating_profit',
            'ìˆœì´ìµ': 'net_profit', 'net_profit': 'net_profit',
            'ROE': 'roe', 'roe': 'roe',
            'ë¶€ì±„ë¹„ìœ¨': 'debt_ratio', 'debt_ratio': 'debt_ratio',
            'ì˜ì—…ì´ìµë¥ ': 'operating_margin', 'operating_margin': 'operating_margin',
        }
        normalized = [metric_alias.get(m, m) for m in comparison_metrics]
        wanted = set(normalized)

        # 2) í—¬í¼: ë°ì´í„° íšë“
        def parse_amount(val: str) -> float:
            if not val or val == '-':
                return 0.0
            s = str(val).replace(',', '').strip()
            neg = s.startswith('(') and s.endswith(')')
            if neg:
                s = s[1:-1]
            try:
                num = float(s)
            except Exception:
                return 0.0
            return -num if neg else num

        def fetch_df(corp_code: str, reprt_code: str, fs_div: str) -> pd.DataFrame:
            url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
            params = {'crtfc_key': API_KEY,'corp_code': corp_code,'bsns_year': bsns_year,'reprt_code': reprt_code,'fs_div': fs_div}
            j = requests.get(url, params=params).json()
            if j.get('status') != '000':
                return pd.DataFrame()
            return pd.DataFrame(j.get('list', []))

        def get_value(df: pd.DataFrame, sj_candidates: List[str], patterns: List[str]) -> float:
            target = df[df['sj_nm'].isin(sj_candidates)] if 'sj_nm' in df.columns else df
            if target.empty:
                return 0.0
            # 1) ê³„ì •ëª…ìœ¼ë¡œ ìš°ì„  ë§¤ì¹­
            for pattern in patterns:
                try:
                    m = target[target['account_nm'].str.contains(pattern, na=False, regex=True)]
                except Exception:
                    m = pd.DataFrame()
                if not m.empty:
                    for col in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount']:
                        if col in m.columns:
                            amt = parse_amount(m.iloc[0][col])
                            if amt != 0.0:
                                return amt
            # 2) account_idë¡œ ë³´ì¡° ë§¤ì¹­ (IFRS í‘œì¤€ ì½”ë“œ)
            if 'account_id' in target.columns:
                id_patterns = ['ProfitLoss', 'NetIncome', 'ComprehensiveIncome', 'ProfitLossAttributableToOwnersOfParent']
                for pid in id_patterns:
                    m2 = target[target['account_id'].str.contains(pid, na=False, regex=False)]
                    if not m2.empty:
                        for col in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount']:
                            if col in m2.columns:
                                amt = parse_amount(m2.iloc[0][col])
                                if amt != 0.0:
                                    return amt
            return 0.0

        # 3) ê° íšŒì‚¬ë³„ ìˆ˜ì§‘/ê³„ì‚°
        comparison_data: Dict[str, Dict[str, Any]] = {}
        for company in companies:
            try:
                corp_code = await get_corp_code(company)
                df = pd.DataFrame()
                for rc, fd in [('11014','CFS'), ('11014','OFS'), ('11013','CFS')]:
                    df = fetch_df(corp_code, rc, fd)
                    if not df.empty:
                        break
                if df.empty:
                    comparison_data[company] = {'ì˜¤ë¥˜': 'ë°ì´í„° ì—†ìŒ'}
                    continue

                total_assets = get_value(df, ['ì¬ë¬´ìƒíƒœí‘œ'], ['ìì‚°ì´ê³„'])
                total_equity = get_value(df, ['ì¬ë¬´ìƒíƒœí‘œ'], ['ìë³¸ì´ê³„'])
                total_liabilities = get_value(df, ['ì¬ë¬´ìƒíƒœí‘œ'], ['ë¶€ì±„ì´ê³„'])
                revenue = get_value(df, ['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë§¤ì¶œì•¡','ìˆ˜ìµ\(ë§¤ì¶œì•¡\)','ì˜ì—…ìˆ˜ìµ'])
                operating_profit = get_value(df, ['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ì˜ì—…ì´ìµ'])
                net_profit = get_value(df, ['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë‹¹ê¸°ìˆœì´ìµ','ë‹¹ê¸°ìˆœì´ìµ\(ì†ì‹¤\)','ì§€ë°°ì£¼ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì§€ë°°ê¸°ì—…\s*ì†Œìœ ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì—°ê²°ë‹¹ê¸°ìˆœì´ìµ'])

                metrics: Dict[str, Any] = {}
                if 'revenue' in wanted:
                    metrics['ë§¤ì¶œì•¡'] = revenue / 100000000
                if 'operating_profit' in wanted:
                    metrics['ì˜ì—…ì´ìµ'] = operating_profit / 100000000
                if 'net_profit' in wanted:
                    metrics['ìˆœì´ìµ'] = net_profit / 100000000
                if 'roe' in wanted and total_equity > 0 and net_profit != 0:
                    metrics['ROE'] = (net_profit / total_equity) * 100
                if 'debt_ratio' in wanted and total_equity > 0:
                    metrics['ë¶€ì±„ë¹„ìœ¨'] = (total_liabilities / total_equity) * 100
                if 'operating_margin' in wanted and revenue > 0:
                    metrics['ì˜ì—…ì´ìµë¥ '] = (operating_profit / revenue) * 100
                comparison_data[company] = metrics
            except Exception as company_error:
                comparison_data[company] = {"ì˜¤ë¥˜": str(company_error)}

        # 4) í‘œ ìƒì„±
        result = f"## ê¸°ì—… ì¬ë¬´ì§€í‘œ ë¹„êµ ({bsns_year}ë…„)\n\n"
        if not comparison_data:
            return [types.TextContent(type="text", text="ë¹„êµí•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")]
        metrics_list = set()
        for d in comparison_data.values():
            if isinstance(d, dict):
                metrics_list.update(d.keys())
        metrics_list = [m for m in ['ë§¤ì¶œì•¡','ì˜ì—…ì´ìµ','ìˆœì´ìµ','ROE','ë¶€ì±„ë¹„ìœ¨','ì˜ì—…ì´ìµë¥ '] if m in metrics_list]

        result += "| ì§€í‘œ |" + " ".join(f"{c} |" for c in companies) + "\n"
        result += "|------|" + ("------|" * len(companies)) + "\n"
        for metric in metrics_list:
            result += f"| **{metric}** |"
            for company in companies:
                val = comparison_data.get(company, {}).get(metric)
                if val is None:
                    result += " - |"
                    continue
                if isinstance(val, float):
                    if metric in ['ë§¤ì¶œì•¡','ì˜ì—…ì´ìµ','ìˆœì´ìµ']:
                        result += f" {val:,.1f}ì–µì› |"
                    elif metric in ['ROE','ë¶€ì±„ë¹„ìœ¨','ì˜ì—…ì´ìµë¥ ']:
                        result += f" {val:.2f}% |"
                    else:
                        result += f" {val:.2f} |"
                else:
                    result += f" {val} |"
            result += "\n"

        if visualization:
            # ê°„ë‹¨í•œ ì°¨íŠ¸ ë°ì´í„°(ë§‰ëŒ€ ê·¸ë˜í”„ìš©) í¬í•¨
            chart = {
                'metrics': metrics_list,
                'series': {company: [comparison_data.get(company, {}).get(m) for m in metrics_list] for company in companies}
            }
            result += "\n### ì‹œê°í™” ë°ì´í„°\n" + json.dumps(chart, ensure_ascii=False)
        return [types.TextContent(type="text", text=result)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"ì¬ë¬´ì§€í‘œ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ë‰´ìŠ¤/ê°ì„±/ì´ë²¤íŠ¸ ë„êµ¬ ë˜í¼
async def get_company_news(corp_name: str, search_period: str, news_categories: List[str], include_sentiment: bool) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        news_data = await news_analyzer.search_company_news(corp_name, search_period)
        result_text = f"""# ğŸ“° {corp_name} ìµœê·¼ ë‰´ìŠ¤ ë¶„ì„

## ğŸ“Š ìˆ˜ì§‘ ì •ë³´
- **ê²€ìƒ‰ ê¸°ê°„**: {search_period}
- **ìˆ˜ì§‘ëœ ê¸°ì‚¬**: {news_data.get('total_articles', 0)}ê°œ
- **ë°ì´í„° ì¶œì²˜**: {news_data.get('data_source', 'N/A')}
- **ìˆ˜ì§‘ ì‹œì **: {news_data.get('search_timestamp', 'N/A')}

## ğŸ“‹ ì£¼ìš” ë‰´ìŠ¤
"""
        for i, article in enumerate(news_data.get('articles', [])[:5], 1):
            result_text += f"""### {i}. {article.get('title', 'N/A')}
- **ë°œí–‰ì¼**: {article.get('published_date', 'N/A')}
- **ì¶œì²˜**: {article.get('source', 'N/A')}
- **ë‚´ìš©**: {article.get('content', 'N/A')[:200]}...

"""
        if include_sentiment:
            total_articles = len(news_data.get('articles', []))
            if total_articles > 0:
                positive_count = sum(1 for article in news_data.get('articles', []) if any(word in (article.get('title','') + article.get('content','')).lower() for word in ['ì„±ì¥','ì¦ê°€','ìƒìŠ¹','ì„±ê³µ','ê¸ì •']))
                sentiment_ratio = positive_count / total_articles
                sentiment_summary = 'ê¸ì •ì ' if sentiment_ratio > 0.6 else 'ë¶€ì •ì ' if sentiment_ratio < 0.4 else 'ì¤‘ë¦½ì '
                result_text += f"## ğŸ’­ ê°ì„± ë¶„ì„ ìš”ì•½\n- **ì „ì²´ ê°ì„±**: {sentiment_summary}\n- **ê¸ì •ì  ê¸°ì‚¬ ë¹„ìœ¨**: {sentiment_ratio:.1%}\n"
        result_text += f"\n---\n*ë¶„ì„ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        return [types.TextContent(type="text", text=result_text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def analyze_news_sentiment(corp_name: str, search_period: str, analysis_depth: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        sentiment_result = await news_analyzer.analyze_company_news_sentiment(corp_name, search_period, analysis_depth)
        result_text = f"""# ğŸ’­ {corp_name} ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê²°ê³¼

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ë¶„ì„ ê¸°ê°„**: {sentiment_result.get('analysis_period', 'N/A')}
- **ë¶„ì„ ê¹Šì´**: {sentiment_result.get('analysis_depth', 'N/A')}
- **ë¶„ì„ ê¸°ì‚¬ ìˆ˜**: {sentiment_result.get('total_articles_analyzed', 0)}ê°œ
- **í‰ê·  ê°ì„± ì ìˆ˜**: {sentiment_result.get('average_sentiment_score', 0):.3f}

## ğŸ¯ ê°ì„± ë¶„í¬
- **ê¸ì •**: {sentiment_result.get('sentiment_distribution', {}).get('positive', 0)}ê°œ
- **ì¤‘ë¦½**: {sentiment_result.get('sentiment_distribution', {}).get('neutral', 0)}ê°œ
- **ë¶€ì •**: {sentiment_result.get('sentiment_distribution', {}).get('negative', 0)}ê°œ
"""
        for article in sentiment_result.get('article_sentiments', [])[:5]:
            result_text += f"""\n### {article.get('title', 'N/A')}
- **ê°ì„± ì ìˆ˜**: {article.get('sentiment_score', 0):.3f}
- **ê°ì„± ë¶„ë¥˜**: {article.get('sentiment_label', 'N/A')}
- **í‚¤ì›Œë“œ**: {', '.join(article.get('detected_keywords', [])[:3])}
"""
        result_text += f"\n---\n*ë¶„ì„ ì™„ë£Œ: {sentiment_result.get('analysis_timestamp', 'N/A')}*\n*ë°ì´í„° ì¶œì²˜: {sentiment_result.get('data_source', 'N/A')}*\n"
        return [types.TextContent(type="text", text=result_text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def detect_financial_events(corp_name: str, monitoring_period: int, event_types: List[str]) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        events_result = await news_analyzer.detect_market_events(corp_name, monitoring_period)
        result_text = f"""# ğŸ¯ {corp_name} ì¬ë¬´ ì´ë²¤íŠ¸ íƒì§€ ê²°ê³¼

## ğŸ“Š íƒì§€ ê°œìš”
- **ëª¨ë‹ˆí„°ë§ ê¸°ê°„**: {events_result.get('monitoring_period_days', 0)}ì¼
- **íƒì§€ëœ ì´ë²¤íŠ¸**: {events_result.get('total_events_detected', 0)}ê°œ
- **ì´ë²¤íŠ¸ ìœ í˜•**: {', '.join(events_result.get('event_types_found', []))}

## ğŸ“‹ ì´ë²¤íŠ¸ ìƒì„¸
"""
        for event_type, events in (events_result.get('event_summary', {}) or {}).items():
            event_name = event_type.replace('_', ' ').title()
            result_text += f"### {event_name}\n- **íƒì§€ ê±´ìˆ˜**: {len(events)}ê°œ\n"
            for event in events[:3]:
                result_text += f"  - {event.get('article_title','N/A')} ({event.get('article_date','N/A')})\n"
            result_text += "\n"
        if not events_result.get('event_summary'):
            result_text += "- íƒì§€ëœ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        result_text += f"\n---\n*íƒì§€ ì™„ë£Œ: {events_result.get('detection_timestamp', 'N/A')}*\n*ë°ì´í„° ì¶œì²˜: {events_result.get('data_source', 'N/A')}*\n"
        return [types.TextContent(type="text", text=result_text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ì´ë²¤íŠ¸ íƒì§€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: íˆ¬ì ì‹ í˜¸ ë° ë¦¬í¬íŠ¸
async def generate_investment_signal(corp_name: str, analysis_period: int, weight_config: Dict[str, float], risk_tolerance: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        # ê°„ì†Œí™”: ê±´ê°•ì„±/ë‰´ìŠ¤/ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ì•„ ì ìˆ˜í™” (ìƒì„¸ ë¡œì§ì€ backup ì°¸ê³ )
        # ì—¬ê¸°ì„œëŠ” news_analyzerì™€ ê°„ë‹¨í•œ ê°€ì¤‘ í•©ìœ¼ë¡œ ëŒ€ì²´
        sentiment = await news_analyzer.analyze_company_news_sentiment(corp_name, "week", "detailed")
        avg_sent = sentiment.get('average_sentiment_score', 0.0)
        total_score = 50 + avg_sent * 50
        signal = 'STRONG BUY' if total_score >= 85 else 'BUY' if total_score >= 70 else 'HOLD' if total_score >= 50 else 'SELL'
        text = f"""# ğŸ¯ {corp_name} íˆ¬ì ì‹ í˜¸ ë¶„ì„

## ğŸ“Š ì¢…í•© íˆ¬ì ì‹ í˜¸
- **ì‹ í˜¸**: {signal}
- **ì‹ í˜¸ ì ìˆ˜**: {total_score:.1f}/100ì 
- **ë¦¬ìŠ¤í¬ í—ˆìš©ë„**: {risk_tolerance.title()}

## ğŸ’¡ ìš”ì•½
- ìµœê·¼ ë‰´ìŠ¤ ê°ì„± ê¸°ë°˜ ê°„ë‹¨ ì‹ í˜¸ì…ë‹ˆë‹¤. ìƒì„¸ ì¢…í•© ë¶„ì„ ë¡œì§ì€ ì°¨í›„ ê³ ë„í™” ì˜ˆì •ì…ë‹ˆë‹¤.
"""
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ íˆ¬ì ì‹ í˜¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def generate_summary_report(corp_name: str, report_type: str, include_charts: bool, analysis_depth: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        # ê°„ë‹¨ ë˜í¼: ëª¨ë“ˆì—ì„œ ë¦¬í¬íŠ¸ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì€ report_generator ë‚´ë¶€)
        analysis_data = {"corp_name": corp_name, "analysis_depth": analysis_depth}
        report_result = await report_generator.generate_comprehensive_report(corp_name, analysis_data)
        if report_result.get('success'):
            return [types.TextContent(type="text", text=report_result.get('report_content',''))]
        return [types.TextContent(type="text", text=f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {report_result.get('metadata',{}).get('error','ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def export_to_pdf(corp_name: str, report_content: str, include_metadata: bool, page_format: str) -> List[types.TextContent]:
    try:
        try:
            from reportlab.lib.pagesizes import letter, A4
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
            from reportlab.lib.styles import getSampleStyleSheet
            import io, base64
        except Exception:
            return [types.TextContent(type="text", text="âŒ PDF ìƒì„±ì„ ìœ„í•œ reportlab ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")]
        buffer = io.BytesIO()
        page_size = A4 if page_format == "A4" else letter
        doc = SimpleDocTemplate(buffer, pagesize=page_size)
        styles = getSampleStyleSheet()
        story = [Paragraph(f"{corp_name} ê¸°ì—… ë¶„ì„ ë¦¬í¬íŠ¸", styles['Title']), Spacer(1, 12)]
        if include_metadata:
            story.append(Paragraph(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), styles['Normal']))
            story.append(Spacer(1, 12))
        for line in report_content.split('\n'):
            if line.strip():
                story.append(Paragraph(line, styles['Normal']))
                story.append(Spacer(1, 6))
        doc.build(story)
        pdf_data = buffer.getvalue(); buffer.close()
        pdf_base64 = base64.b64encode(pdf_data).decode('utf-8')
        text = f"""# ğŸ“„ PDF ë‚´ë³´ë‚´ê¸° ì™„ë£Œ

- **ê¸°ì—…ëª…**: {corp_name}
- **íŒŒì¼ í¬ê¸°**: {len(pdf_data):,} bytes

```
{pdf_base64[:200]}...
```
"""
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ PDF ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: í¬íŠ¸í´ë¦¬ì˜¤/ê²½ìŸ/ì—…ê³„ ë¦¬í¬íŠ¸
async def optimize_portfolio(companies: List[str], investment_amount: int, risk_tolerance: str, optimization_method: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        portfolio_result = await portfolio_analyzer.optimize_portfolio(companies, investment_amount, risk_tolerance, optimization_method)
        text = f"""# ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê²°ê³¼

## ğŸ¯ ìµœì í™” ì„¤ì •
- **ê¸°ì—… êµ¬ì„±**: {', '.join(companies)}
- **ì´ íˆ¬ìê¸ˆì•¡**: {investment_amount:,}ì›
- **ë¦¬ìŠ¤í¬ í—ˆìš©ë„**: {risk_tolerance.title()}
- **ìµœì í™” ë°©ë²•**: {optimization_method.title()}

## ğŸ’° ìµœì  íˆ¬ì ë¹„ì¤‘
"""
        for company, weight in (portfolio_result.get('optimal_weights', {}) or {}).items():
            allocation = (portfolio_result.get('allocations', {}) or {}).get(company, 0)
            text += f"- **{company}**: {weight:.1%} ({allocation:,.0f}ì›)\n"
        text += f"\n## ğŸ“ˆ ì˜ˆìƒ ì„±ê³¼\n- **ì—°ê°„ ê¸°ëŒ€ìˆ˜ìµë¥ **: {portfolio_result.get('expected_annual_return', 0):.1f}%\n- **ì—°ê°„ ë³€ë™ì„±**: {portfolio_result.get('annual_volatility', 0):.1f}%\n- **ìƒ¤í”„ ë¹„ìœ¨**: {portfolio_result.get('sharpe_ratio', 0):.2f}\n"
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def analyze_competitive_position(corp_name: str, competitors: List[str], analysis_metrics: List[str], include_swot: bool) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        competitive_result = await benchmark_analyzer.analyze_competitive_position(corp_name, competitors, analysis_metrics)
        text = f"""# âš”ï¸ {corp_name} ê²½ìŸ í¬ì§€ì…˜ ë¶„ì„

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ëŒ€ìƒ ê¸°ì—…**: {corp_name}
- **ê²½ìŸì‚¬**: {', '.join(competitors)}
- **ë¶„ì„ ì§€í‘œ**: {', '.join(analysis_metrics)}
- **ì‹œì¥ í¬ì§€ì…˜**: {competitive_result.get('market_position', 'N/A')}
"""
        if include_swot and 'swot_analysis' in competitive_result:
            swot = competitive_result['swot_analysis']
            text += f"""\n## ğŸ¯ SWOT ë¶„ì„

### âš¡ ê°•ì  (Strengths)
{chr(10).join(f"- {s}" for s in swot.get('strengths', []))}

### âš ï¸ ì•½ì  (Weaknesses)
{chr(10).join(f"- {w}" for w in swot.get('weaknesses', []))}

### ğŸŒŸ ê¸°íšŒ (Opportunities)
{chr(10).join(f"- {o}" for o in swot.get('opportunities', []))}

### ğŸš¨ ìœ„í˜‘ (Threats)
{chr(10).join(f"- {t}" for t in swot.get('threats', []))}
"""
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ê²½ìŸ í¬ì§€ì…˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def generate_industry_report(industry: str, report_type: str, include_rankings: bool) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        industry_result = await benchmark_analyzer.generate_industry_report(industry, report_type)
        text = f"""# ğŸ­ {industry} ì—…ê³„ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š ì—…ê³„ ê°œìš”
- **ì—…ì¢…**: {industry}
- **ë¶„ì„ ê¸°ì—… ìˆ˜**: {industry_result.get('companies_analyzed', 0)}ê°œ
- **ë¦¬í¬íŠ¸ ìœ í˜•**: {report_type.title()}

## ğŸŒŸ ì—…ê³„ íŠ¹ì„±
{industry_result.get('industry_overview', {}).get('market_characteristics', 'N/A')}

## ğŸ” ì£¼ìš” íŠ¸ë Œë“œ
"""
        for trend in industry_result.get('industry_overview', {}).get('key_trends', []):
            text += f"- {trend}\n"
        if include_rankings:
            text += "\n## ğŸ“‹ ê¸°ì—… ìˆœìœ„ (ì£¼ìš” ì§€í‘œ ê¸°ì¤€)\n- ROE, ë§¤ì¶œì•¡ì¦ê°€ìœ¨ ë“± í•µì‹¬ ì§€í‘œ ì¢…í•© í‰ê°€\n"
        text += f"\n---\n*ë¦¬í¬íŠ¸ ìƒì„±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ì—…ê³„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

def _get_report_name(reprt_code: str) -> str:
    """ë³´ê³ ì„œ ì½”ë“œë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    code_names = {
        '11011': '1ë¶„ê¸°ë³´ê³ ì„œ',
        '11012': 'ë°˜ê¸°ë³´ê³ ì„œ', 
        '11013': '3ë¶„ê¸°ë³´ê³ ì„œ',
        '11014': 'ì‚¬ì—…ë³´ê³ ì„œ',
        '11001': 'ì •ê¸°ê³µì‹œ'
    }
    return code_names.get(reprt_code, f'ë³´ê³ ì„œ({reprt_code})')

@app.list_tools()
async def handle_list_tools() -> list[Tool]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤"""
    return [
        Tool(
            name="set_dart_api_key",
            description="DART API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "api_key": {
                        "type": "string",
                        "description": "DART API í‚¤"
                    }
                },
                "required": ["api_key"]
            }
        ),
        Tool(
            name="get_company_info",
            description="ê¸°ì—…ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {
                        "type": "string",
                        "description": "íšŒì‚¬ëª…"
                    }
                },
                "required": ["corp_name"]
            }
        ),
        Tool(
            name="get_financial_statements",
            description="ê¸°ì—…ì˜ ì¬ë¬´ì œí‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {
                        "type": "string",
                        "description": "íšŒì‚¬ëª…"
                    },
                    "bsns_year": {
                        "type": "string",
                        "description": "ì‚¬ì—…ì—°ë„ (ì˜ˆ: 2024)",
                        "default": "2024"
                    },
                    "reprt_code": {
                        "type": "string",
                        "description": "ë³´ê³ ì„œ ì½”ë“œ (11011: 1ë¶„ê¸°, 11012: ë°˜ê¸°, 11013: 3ë¶„ê¸°, 11014: ì‚¬ì—…ë³´ê³ ì„œ)",
                        "default": "11014"
                    },
                    "fs_div": {
                        "type": "string",
                        "description": "ì¬ë¬´ì œí‘œ êµ¬ë¶„ (CFS: ì—°ê²°, OFS: ë³„ë„)",
                        "default": "CFS"
                    },
                    "statement_type": {
                        "type": "string",
                        "description": "ì¬ë¬´ì œí‘œ ì¢…ë¥˜ (ì¬ë¬´ìƒíƒœí‘œ, ì†ìµê³„ì‚°ì„œ, í˜„ê¸ˆíë¦„í‘œ, ìë³¸ë³€ë™í‘œ)",
                        "default": "ì†ìµê³„ì‚°ì„œ"
                    }
                },
                "required": ["corp_name"]
            }
        ),
        Tool(
            name="get_financial_ratios",
            description="ì£¼ìš” ì¬ë¬´ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "bsns_year": {"type": "string", "description": "ì‚¬ì—…ì—°ë„ (ì˜ˆ: 2024)", "default": "2024"},
                    "ratio_categories": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["profitability", "stability", "activity", "growth"]},
                        "default": ["profitability", "stability"]
                    },
                    "include_industry_avg": {"type": "boolean", "default": True}
                },
                "required": ["corp_name", "bsns_year"]
            }
        ),
        Tool(
            name="analyze_time_series",
            description="ê¸°ì—…ì˜ ì¬ë¬´ ì„±ê³¼ ì‹œê³„ì—´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string"},
                    "analysis_period": {"type": "integer", "default": 5},
                    "metrics": {"type": "array", "items": {"type": "string"}, "default": ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]},
                    "forecast_periods": {"type": "integer", "default": 8}
                },
                "required": ["corp_name"]
            }
        ),
        Tool(
            name="compare_with_industry",
            description="ê¸°ì—…ì„ ë™ì¢… ì—…ê³„ì™€ ë²¤ì¹˜ë§ˆí¬ ë¹„êµí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string"},
                    "industry": {"type": "string", "enum": ["ë°˜ë„ì²´", "ì „ê¸°ì „ì", "í™”í•™", "ìë™ì°¨", "ê¸ˆìœµ", "ì¸í„°ë„·"]},
                    "comparison_metrics": {"type": "array", "items": {"type": "string"}, "default": ["ROE", "ROA", "ë¶€ì±„ë¹„ìœ¨"]},
                    "analysis_type": {"type": "string", "enum": ["basic", "detailed"], "default": "basic"}
                },
                "required": ["corp_name", "industry"]
            }
        ),
        Tool(
            name="get_disclosure_list",
            description="ê¸°ì—…ì˜ ê³µì‹œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "bgn_de": {"type": "string", "description": "ê²€ìƒ‰ ì‹œì‘ì¼ (YYYYMMDD)"},
                    "end_de": {"type": "string", "description": "ê²€ìƒ‰ ì¢…ë£Œì¼ (YYYYMMDD)"},
                    "page_count": {"type": "integer", "description": "í˜ì´ì§€ ë‹¹ ë°ì´í„° ìˆ˜", "default": 10}
                },
                "required": ["corp_name", "bgn_de", "end_de"]
            }
        ),
        Tool(
            name="compare_financials",
            description="ì—¬ëŸ¬ ê¸°ì—…ì˜ ì¬ë¬´ì§€í‘œë¥¼ ë¹„êµí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "companies": {"type": "array", "items": {"type": "string"}, "description": "ë¹„êµí•  ê¸°ì—… ëª©ë¡"},
                    "bsns_year": {"type": "string", "description": "ë¹„êµí•  ì—°ë„ (ì˜ˆ: 2024)", "default": "2024"},
                    "comparison_metrics": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ", "ROE", "ë¶€ì±„ë¹„ìœ¨", "ì˜ì—…ì´ìµë¥ "]},
                        "default": ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]
                    },
                    "visualization": {"type": "boolean", "default": True, "description": "ì°¨íŠ¸ ì‹œê°í™” í¬í•¨ ì—¬ë¶€"}
                },
                "required": ["companies", "bsns_year"]
            }
        ),
        Tool(
            name="get_company_news",
            description="ê¸°ì—…ì˜ ìµœê·¼ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "search_period": {"type": "string", "description": "ê²€ìƒ‰í•  ê¸°ê°„ (ì˜ˆ: 1ë…„, 6ê°œì›”, 1ê°œì›”)", "default": "1ë…„"},
                    "news_categories": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["ì „ì²´", "ê²½ì œ", "ì‚°ì—…", "ê¸ˆìœµ", "ì •ì±…", "ê¸°ìˆ ", "ì •ë³´ë³´í˜¸", "ê¸°íƒ€"]},
                        "default": ["ì „ì²´"]
                    },
                    "include_sentiment": {"type": "boolean", "default": True, "description": "ê°ì„± ë¶„ì„ í¬í•¨ ì—¬ë¶€"}
                },
                "required": ["corp_name", "search_period"]
            }
        ),
        Tool(
            name="analyze_news_sentiment",
            description="ê¸°ì—… ë‰´ìŠ¤ì˜ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "search_period": {"type": "string", "description": "ë¶„ì„í•  ê¸°ê°„ (ì˜ˆ: 1ë…„, 6ê°œì›”, 1ê°œì›”)", "default": "1ë…„"},
                    "analysis_depth": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¶„ì„ ê¹Šì´"}
                },
                "required": ["corp_name", "search_period"]
            }
        ),
        Tool(
            name="detect_financial_events",
            description="ê¸°ì—…ì˜ ì¬ë¬´ ì´ë²¤íŠ¸ë¥¼ íƒì§€í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "monitoring_period": {"type": "integer", "default": 30, "description": "ëª¨ë‹ˆí„°ë§ ê¸°ê°„ (ì¼)"},
                    "event_types": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["ì „ì²´", "ì‹ ê·œ ê³µì‹œ", "ì‹ ê·œ ì¬ë¬´ì œí‘œ", "ì‹ ê·œ ì†ìµê³„ì‚°ì„œ", "ì‹ ê·œ ì¬ë¬´ìƒíƒœí‘œ", "ì‹ ê·œ í˜„ê¸ˆíë¦„í‘œ", "ì‹ ê·œ ìë³¸ë³€ë™í‘œ", "ê¸°íƒ€"]},
                        "default": ["ì „ì²´"]
                    }
                },
                "required": ["corp_name", "monitoring_period"]
            }
        ),
        Tool(
            name="generate_investment_signal",
            description="ê¸°ì—…ì˜ íˆ¬ì ì‹ í˜¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "analysis_period": {"type": "integer", "default": 5, "description": "ë¶„ì„ ê¸°ê°„ (ë…„)"},
                    "weight_config": {
                        "type": "object",
                        "properties": {
                            "news_sentiment": {"type": "number", "default": 0.5, "description": "ë‰´ìŠ¤ ê°ì„± ê°€ì¤‘ì¹˜"},
                            "market_events": {"type": "number", "default": 0.3, "description": "ì¬ë¬´ ì´ë²¤íŠ¸ ê°€ì¤‘ì¹˜"},
                            "financial_ratios": {"type": "number", "default": 0.2, "description": "ì¬ë¬´ë¹„ìœ¨ ê°€ì¤‘ì¹˜"}
                        },
                        "required": ["news_sentiment", "market_events", "financial_ratios"]
                    },
                    "risk_tolerance": {"type": "string", "enum": ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"], "default": "ë³´í†µ", "description": "ë¦¬ìŠ¤í¬ í—ˆìš©ë„"}
                },
                "required": ["corp_name", "analysis_period", "weight_config", "risk_tolerance"]
            }
        ),
        Tool(
            name="generate_summary_report",
            description="ê¸°ì—…ì˜ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "report_type": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¦¬í¬íŠ¸ ìœ í˜•"},
                    "include_charts": {"type": "boolean", "default": True, "description": "ì°¨íŠ¸ í¬í•¨ ì—¬ë¶€"},
                    "analysis_depth": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¶„ì„ ê¹Šì´"}
                },
                "required": ["corp_name", "report_type"]
            }
        ),
        Tool(
            name="export_to_pdf",
            description="ë¦¬í¬íŠ¸ ë‚´ìš©ì„ PDFë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "report_content": {"type": "string", "description": "ë¦¬í¬íŠ¸ ë‚´ìš©"},
                    "include_metadata": {"type": "boolean", "default": True, "description": "ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€"},
                    "page_format": {"type": "string", "enum": ["A4", "Letter"], "default": "A4", "description": "í˜ì´ì§€ í˜•ì‹"}
                },
                "required": ["corp_name", "report_content"]
            }
        ),
        Tool(
            name="optimize_portfolio",
            description="í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "companies": {"type": "array", "items": {"type": "string"}, "description": "í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ê¸°ì—… ëª©ë¡"},
                    "investment_amount": {"type": "integer", "default": 100000000, "description": "ì´ íˆ¬ìê¸ˆì•¡ (ì›)"},
                    "risk_tolerance": {"type": "string", "enum": ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"], "default": "ë³´í†µ", "description": "ë¦¬ìŠ¤í¬ í—ˆìš©ë„"},
                    "optimization_method": {"type": "string", "enum": ["ìµœëŒ€ ìˆ˜ìµ", "ìµœì†Œ ë¦¬ìŠ¤í¬", "ê· í˜•"], "default": "ê· í˜•", "description": "ìµœì í™” ë°©ë²•"}
                },
                "required": ["companies", "investment_amount", "risk_tolerance", "optimization_method"]
            }
        ),
        Tool(
            name="analyze_competitive_position",
            description="ê¸°ì—…ì˜ ê²½ìŸ í¬ì§€ì…˜ì„ ë¶„ì„í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "competitors": {"type": "array", "items": {"type": "string"}, "description": "ê²½ìŸì‚¬ ëª©ë¡"},
                    "analysis_metrics": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["SWOT", "ì¬ë¬´ë¹„ìœ¨", "ì‹œì¥ ì ìœ ìœ¨", "ì„±ì¥ì„±", "ìœ„í—˜ì„±"]},
                        "default": ["SWOT", "ì¬ë¬´ë¹„ìœ¨"]
                    },
                    "include_swot": {"type": "boolean", "default": True, "description": "SWOT ë¶„ì„ í¬í•¨ ì—¬ë¶€"}
                },
                "required": ["corp_name", "competitors"]
            }
        ),
        Tool(
            name="generate_industry_report",
            description="íŠ¹ì • ì—…ê³„ì˜ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "industry": {"type": "string", "description": "ì—…ê³„ëª… (ì˜ˆ: ë°˜ë„ì²´, ì „ê¸°ì „ì, í™”í•™, ìë™ì°¨, ê¸ˆìœµ, ì¸í„°ë„·)"},
                    "report_type": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¦¬í¬íŠ¸ ìœ í˜•"},
                    "include_rankings": {"type": "boolean", "default": True, "description": "ê¸°ì—… ìˆœìœ„ í¬í•¨ ì—¬ë¶€"}
                },
                "required": ["industry", "report_type"]
            }
        )
    ]

@app.call_tool()
async def handle_call_tool(name: str, arguments: dict) -> list[types.TextContent]:
    """ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤"""
    if name == "set_dart_api_key":
        return await set_dart_api_key(arguments["api_key"])
    elif name == "get_company_info":
        return await get_company_info(arguments["corp_name"])
    elif name == "get_financial_statements":
        return await get_financial_statements(
            arguments["corp_name"],
            arguments.get("bsns_year", "2024"),
            arguments.get("reprt_code", "11014"),
            arguments.get("fs_div", "CFS"),
            arguments.get("statement_type", "ì†ìµê³„ì‚°ì„œ")
        )
    elif name == "get_financial_ratios":
        return await get_financial_ratios(
            arguments["corp_name"],
            arguments["bsns_year"],
            arguments.get("ratio_categories", ["profitability", "stability"]),
            arguments.get("include_industry_avg", True)
        )
    elif name == "analyze_time_series":
        return await analyze_time_series(
            arguments["corp_name"],
            arguments.get("analysis_period", 5),
            arguments.get("metrics", ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]),
            arguments.get("forecast_periods", 8)
        )
    elif name == "compare_with_industry":
        return await compare_with_industry(
            arguments["corp_name"],
            arguments["industry"],
            arguments.get("comparison_metrics", ["ROE", "ROA", "ë¶€ì±„ë¹„ìœ¨"]),
            arguments.get("analysis_type", "basic")
        )
    elif name == "get_disclosure_list":
        return await get_disclosure_list(
            arguments["corp_name"],
            arguments["bgn_de"],
            arguments["end_de"],
            arguments.get("page_count", 10)
        )
    elif name == "compare_financials":
        return await compare_financials(
            arguments["companies"],
            arguments["bsns_year"],
            arguments.get("comparison_metrics", ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]),
            arguments.get("visualization", True)
        )
    elif name == "get_company_news":
        return await get_company_news(
            arguments["corp_name"],
            arguments["search_period"],
            arguments.get("news_categories", ["ì „ì²´"]),
            arguments.get("include_sentiment", True)
        )
    elif name == "analyze_news_sentiment":
        return await analyze_news_sentiment(
            arguments["corp_name"],
            arguments["search_period"],
            arguments.get("analysis_depth", "basic")
        )
    elif name == "detect_financial_events":
        return await detect_financial_events(
            arguments["corp_name"],
            arguments["monitoring_period"],
            arguments.get("event_types", ["ì „ì²´"])
        )
    elif name == "generate_investment_signal":
        return await generate_investment_signal(
            arguments["corp_name"],
            arguments["analysis_period"],
            arguments["weight_config"],
            arguments["risk_tolerance"]
        )
    elif name == "generate_summary_report":
        return await generate_summary_report(
            arguments["corp_name"],
            arguments["report_type"],
            arguments.get("include_charts", True),
            arguments.get("analysis_depth", "basic")
        )
    elif name == "export_to_pdf":
        return await export_to_pdf(
            arguments["corp_name"],
            arguments["report_content"],
            arguments.get("include_metadata", True),
            arguments.get("page_format", "A4")
        )
    elif name == "optimize_portfolio":
        return await optimize_portfolio(
            arguments["companies"],
            arguments["investment_amount"],
            arguments["risk_tolerance"],
            arguments["optimization_method"]
        )
    elif name == "analyze_competitive_position":
        return await analyze_competitive_position(
            arguments["corp_name"],
            arguments["competitors"],
            arguments.get("analysis_metrics", ["SWOT", "ì¬ë¬´ë¹„ìœ¨"]),
            arguments.get("include_swot", True)
        )
    elif name == "generate_industry_report":
        return await generate_industry_report(
            arguments["industry"],
            arguments["report_type"],
            arguments.get("include_rankings", True)
        )
    else:
        return [types.TextContent(type="text", text=f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}")]

async def main():
    """MCP ì„œë²„ ë©”ì¸ í•¨ìˆ˜"""
    # stdio_serverë¥¼ ì‚¬ìš©í•˜ì—¬ MCP ì„œë²„ ì‹¤í–‰
    async with stdio_server() as (read_stream, write_stream):
        await app.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="OpenCorpInsight",
                server_version="1.0.0",
                capabilities=app.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )

if __name__ == "__main__":
    asyncio.run(main()) 